{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mzLlDtZci0Un",
        "N6IMIWA2nxJl",
        "B3ImlYcHniFT"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Dataset"
      ],
      "metadata": {
        "id": "mzLlDtZci0Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Kaggle package\n",
        "!pip install kaggle\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d yasserh/housing-prices-dataset\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip housing-prices-dataset.zip -d housing-prices-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jc5EsUpi2P_",
        "outputId": "881a6973-f52d-4a93-b64a-b6cd1cf2585f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Dataset URL: https://www.kaggle.com/datasets/yasserh/housing-prices-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading housing-prices-dataset.zip to /content\n",
            "  0% 0.00/4.63k [00:00<?, ?B/s]\n",
            "100% 4.63k/4.63k [00:00<00:00, 8.80MB/s]\n",
            "Archive:  housing-prices-dataset.zip\n",
            "  inflating: housing-prices-dataset/Housing.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess the Dataset"
      ],
      "metadata": {
        "id": "QSVxN2fgj2ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset"
      ],
      "metadata": {
        "id": "N6IMIWA2nxJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/content/housing-prices-dataset/Housing.csv')\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FHKrjGypkCXf",
        "outputId": "4a06ef17-e1a1-4f1b-f4af-7911d7ff7c5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
              "0  13300000  7420         4          2        3      yes        no       no   \n",
              "1  12250000  8960         4          4        4      yes        no       no   \n",
              "2  12250000  9960         3          2        2      yes        no      yes   \n",
              "3  12215000  7500         4          2        2      yes        no      yes   \n",
              "4  11410000  7420         4          1        2      yes       yes      yes   \n",
              "\n",
              "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
              "0              no             yes        2      yes        furnished  \n",
              "1              no             yes        3       no        furnished  \n",
              "2              no              no        2      yes   semi-furnished  \n",
              "3              no             yes        3      yes        furnished  \n",
              "4              no             yes        2       no        furnished  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9df272ca-8ec0-4713-a3af-646d1d116282\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>area</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>stories</th>\n",
              "      <th>mainroad</th>\n",
              "      <th>guestroom</th>\n",
              "      <th>basement</th>\n",
              "      <th>hotwaterheating</th>\n",
              "      <th>airconditioning</th>\n",
              "      <th>parking</th>\n",
              "      <th>prefarea</th>\n",
              "      <th>furnishingstatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13300000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12250000</td>\n",
              "      <td>8960</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12250000</td>\n",
              "      <td>9960</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>semi-furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12215000</td>\n",
              "      <td>7500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11410000</td>\n",
              "      <td>7420</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>furnished</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9df272ca-8ec0-4713-a3af-646d1d116282')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9df272ca-8ec0-4713-a3af-646d1d116282 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9df272ca-8ec0-4713-a3af-646d1d116282');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86259a63-042b-41a5-9335-a48410a58027\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86259a63-042b-41a5-9335-a48410a58027')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86259a63-042b-41a5-9335-a48410a58027 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 545,\n  \"fields\": [\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1870439,\n        \"min\": 1750000,\n        \"max\": 13300000,\n        \"num_unique_values\": 219,\n        \"samples\": [\n          3773000,\n          5285000,\n          1820000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2170,\n        \"min\": 1650,\n        \"max\": 16200,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          6000,\n          2684,\n          5360\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bathrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stories\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mainroad\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"guestroom\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"basement\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hotwaterheating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airconditioning\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prefarea\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"furnishingstatus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"furnished\",\n          \"semi-furnished\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 1:].values\n",
        "y = dataset.iloc[:, 0].values"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z3GD0QBrkV8E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djg_cQW-m52n",
        "outputId": "6b76f72a-477f-4c76-bd3c-b1ebd0f456b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7420 4 2 3 'yes' 'no' 'no' 'no' 'yes' 2 'yes' 'furnished']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1Dcm1vJm8Fx",
        "outputId": "0f066e6f-cd8b-4d06-9c94-200429dccbc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8960 4 4 4 'yes' 'no' 'no' 'no' 'yes' 3 'no' 'furnished']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting dataset"
      ],
      "metadata": {
        "id": "B3ImlYcHniFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "8syRrd1HlZfd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q0Rw5pHnE2Z",
        "outputId": "c74b6ea4-299e-483d-db89-7c0845e80153"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3620 2 1 1 'yes' 'no' 'no' 'no' 'no' 0 'no' 'unfurnished']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afmgUIbpnIyw",
        "outputId": "b41bbc21-8b8a-4f4e-ba11-fe06c610feea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1750000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Categorical variables"
      ],
      "metadata": {
        "id": "WWUBdUmvnmvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4,5,6,7,8,10,11])], remainder='passthrough')\n",
        "X_train = np.array(ct.fit_transform(X_train))"
      ],
      "metadata": {
        "id": "SCm1O7xXmGOq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(ct.transform(X_test))"
      ],
      "metadata": {
        "id": "16Zrcf4-mfV2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbMKh9tHmqHI",
        "outputId": "211f62c3-b8c2-47d2-fa1d-598585478881"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0 1.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 3620 2 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzppTHJRtTG7",
        "outputId": "b75f92f2-3c0b-4ca8-9861-a5bca2951191"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0 1.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 4000 3 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for missing data"
      ],
      "metadata": {
        "id": "oe4x_JGWpXxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows = np.any(np.isnan(X_train.astype(np.float64)), axis=1)  # Convert to numeric type\n",
        "print(X_train[nan_rows])\n",
        "# no missing data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vFGMf4_in00o",
        "outputId": "16ced649-f2de-40f9-d9b6-bc3788e9c732"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Models"
      ],
      "metadata": {
        "id": "cmpiwgVPps5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "1XR_BnJupv-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "MIgIT3zspyPH",
        "outputId": "ffc6a52c-a502-42d0-8372-18f6a7716c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BedKaDFVp9dS",
        "outputId": "80887b64-3c5a-40d2-b549-1414d274c68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3950288.62  4585000.  ]\n",
            " [ 6173868.82  6083000.  ]\n",
            " [ 4483635.99  4007500.  ]\n",
            " [ 7258732.75  6930000.  ]\n",
            " [ 2836727.58  2940000.  ]\n",
            " [ 7032947.1   6195000.  ]\n",
            " [ 3203851.47  3535000.  ]\n",
            " [ 3270994.01  2940000.  ]\n",
            " [ 3472554.04  3500000.  ]\n",
            " [ 8289978.33  7980000.  ]\n",
            " [ 6605321.63  6755000.  ]\n",
            " [ 3723366.24  3990000.  ]\n",
            " [ 3812376.96  3150000.  ]\n",
            " [ 4548966.85  3290000.  ]\n",
            " [ 4020476.35  4130000.  ]\n",
            " [ 1969836.22  2660000.  ]\n",
            " [ 4057262.98  4410000.  ]\n",
            " [ 3704586.87  3710000.  ]\n",
            " [ 3282767.93  3360000.  ]\n",
            " [ 4609423.65  4270000.  ]\n",
            " [ 5968243.74  5005000.  ]\n",
            " [ 6363698.62  5383000.  ]\n",
            " [ 4751300.32  6440000.  ]\n",
            " [ 2659595.28  1890000.  ]\n",
            " [ 5305573.25  6125000.  ]\n",
            " [ 5680819.59  5460000.  ]\n",
            " [ 5404106.9   5803000.  ]\n",
            " [ 5543050.52  4620000.  ]\n",
            " [ 5768360.48  5530000.  ]\n",
            " [ 5801753.71  5950000.  ]\n",
            " [ 3389277.96  4305000.  ]\n",
            " [ 6399092.03  3640000.  ]\n",
            " [ 7081030.31  5250000.  ]\n",
            " [ 2913042.4   3325000.  ]\n",
            " [ 4498664.01  3703000.  ]\n",
            " [ 5210561.68  4753000.  ]\n",
            " [ 5013457.84  9100000.  ]\n",
            " [ 3707596.71  3500000.  ]\n",
            " [ 2916603.45  3150000.  ]\n",
            " [ 3937761.76  4270000.  ]\n",
            " [ 8041334.2   8960000.  ]\n",
            " [ 4942174.61  4060000.  ]\n",
            " [ 6432605.22  5740000.  ]\n",
            " [ 3511338.78  3129000.  ]\n",
            " [ 3813475.4   3633000.  ]\n",
            " [ 6434856.2   7560000.  ]\n",
            " [ 4447687.03  4620000.  ]\n",
            " [ 2696243.72  3290000.  ]\n",
            " [ 4180018.71  4165000.  ]\n",
            " [ 6455973.26  6650000.  ]\n",
            " [ 4056226.34  4165000.  ]\n",
            " [ 7124571.3   4690000.  ]\n",
            " [ 2530661.68  3150000.  ]\n",
            " [ 3033278.46  3850000.  ]\n",
            " [ 3500830.32  3290000.  ]\n",
            " [ 5119451.02  5075000.  ]\n",
            " [ 7110973.93  6510000.  ]\n",
            " [ 4127705.8   5740000.  ]\n",
            " [ 2970005.37  3780000.  ]\n",
            " [ 4325732.62  4795000.  ]\n",
            " [ 5986119.71  4900000.  ]\n",
            " [ 6824682.69  5460000.  ]\n",
            " [ 3325637.46  3500000.  ]\n",
            " [ 7191804.56  7525000.  ]\n",
            " [ 2609468.55  2835000.  ]\n",
            " [ 5056521.66  5495000.  ]\n",
            " [ 6636269.78  8680000.  ]\n",
            " [ 2565659.89  4200000.  ]\n",
            " [ 3751294.04  4200000.  ]\n",
            " [ 5080427.99  4900000.  ]\n",
            " [ 4281895.69  3332000.  ]\n",
            " [ 7361447.18  6195000.  ]\n",
            " [ 5088033.19  4098500.  ]\n",
            " [ 6022539.93  6650000.  ]\n",
            " [ 4176648.2   3885000.  ]\n",
            " [ 4639478.55  4620000.  ]\n",
            " [ 2898083.35  1960000.  ]\n",
            " [ 7564393.66  6440000.  ]\n",
            " [ 2583102.74  1750000.  ]\n",
            " [ 3764386.73  3605000.  ]\n",
            " [ 4281895.69  3290000.  ]\n",
            " [ 6064669.42  4970000.  ]\n",
            " [ 5199726.51  4613000.  ]\n",
            " [ 5402615.01  3850000.  ]\n",
            " [ 3900783.42  3500000.  ]\n",
            " [ 4206866.27  6107500.  ]\n",
            " [ 4785571.46  3780000.  ]\n",
            " [ 5125782.9   4900000.  ]\n",
            " [ 3843109.12  3570000.  ]\n",
            " [ 4373515.96  4340000.  ]\n",
            " [ 3233779.58  3500000.  ]\n",
            " [ 5800152.86  6300000.  ]\n",
            " [ 3086788.94  3395000.  ]\n",
            " [ 3736808.51  3815000.  ]\n",
            " [ 4475695.33  3920000.  ]\n",
            " [10490600.69 12250000.  ]\n",
            " [ 3044861.09  3080000.  ]\n",
            " [ 7172608.24  9310000.  ]\n",
            " [ 4348859.17  4270000.  ]\n",
            " [ 4508307.37  3780000.  ]\n",
            " [ 6607800.85  5600000.  ]\n",
            " [ 3393091.94  3290000.  ]\n",
            " [ 4545560.49  2380000.  ]\n",
            " [ 3313363.09  5110000.  ]\n",
            " [ 7340959.28  6650000.  ]\n",
            " [ 5235408.6   5810000.  ]\n",
            " [ 4134159.03  4123000.  ]\n",
            " [ 5058911.23  3080000.  ]\n",
            " [ 6279957.32  5530000.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZRXBxzHp_FD",
        "outputId": "e019e34f-a36f-4ff3-ab52-0008a2e26136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6611214250980382"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'linear_regression_model.sav'\n",
        "pickle.dump(regressor, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "0LP1ZDMbqFlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector regression"
      ],
      "metadata": {
        "id": "uu_G1vhkuVhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_svr = y_train.reshape(len(y_train),1)\n",
        "y_test_svr = y_test.reshape(len(y_test),1)"
      ],
      "metadata": {
        "id": "vrq6QG-9vCr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "sc_y = StandardScaler()\n",
        "X_train_svr = sc_X.fit_transform(X_train)\n",
        "y_train_svr = sc_y.fit_transform(y_train_svr)"
      ],
      "metadata": {
        "id": "FCgWIuSAurgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X_train_svr, y_train_svr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "0dWS5xNNux8I",
        "outputId": "a2f6e02f-f14f-491f-aa42-84b4d88f2f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR()"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_test)).reshape(-1,1))\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test_svr),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MfBbyW0Su2bS",
        "outputId": "da9df8c6-b56e-478f-c10d-f50215d29e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3912335.96  4585000.  ]\n",
            " [ 6259503.8   6083000.  ]\n",
            " [ 4046872.61  4007500.  ]\n",
            " [ 5779091.99  6930000.  ]\n",
            " [ 3179226.84  2940000.  ]\n",
            " [ 6885488.2   6195000.  ]\n",
            " [ 3536058.63  3535000.  ]\n",
            " [ 3120252.96  2940000.  ]\n",
            " [ 3412351.84  3500000.  ]\n",
            " [ 8126863.47  7980000.  ]\n",
            " [ 6374431.11  6755000.  ]\n",
            " [ 3834613.46  3990000.  ]\n",
            " [ 4166073.17  3150000.  ]\n",
            " [ 5397971.75  3290000.  ]\n",
            " [ 4663754.19  4130000.  ]\n",
            " [ 2662073.57  2660000.  ]\n",
            " [ 4251577.9   4410000.  ]\n",
            " [ 4096776.74  3710000.  ]\n",
            " [ 3561189.66  3360000.  ]\n",
            " [ 4214584.95  4270000.  ]\n",
            " [ 5523307.34  5005000.  ]\n",
            " [ 6307066.25  5383000.  ]\n",
            " [ 4470800.43  6440000.  ]\n",
            " [ 2880915.86  1890000.  ]\n",
            " [ 5777239.5   6125000.  ]\n",
            " [ 6458146.9   5460000.  ]\n",
            " [ 5622159.63  5803000.  ]\n",
            " [ 5699356.56  4620000.  ]\n",
            " [ 4688037.5   5530000.  ]\n",
            " [ 5683527.48  5950000.  ]\n",
            " [ 3503191.35  4305000.  ]\n",
            " [ 5768364.39  3640000.  ]\n",
            " [ 7210092.17  5250000.  ]\n",
            " [ 2995316.57  3325000.  ]\n",
            " [ 4788075.74  3703000.  ]\n",
            " [ 4283457.64  4753000.  ]\n",
            " [ 4316344.2   9100000.  ]\n",
            " [ 4089353.71  3500000.  ]\n",
            " [ 3119211.18  3150000.  ]\n",
            " [ 4337942.91  4270000.  ]\n",
            " [ 8143274.18  8960000.  ]\n",
            " [ 4318426.24  4060000.  ]\n",
            " [ 6539835.61  5740000.  ]\n",
            " [ 3568108.42  3129000.  ]\n",
            " [ 4036373.19  3633000.  ]\n",
            " [ 6311285.95  7560000.  ]\n",
            " [ 4952852.53  4620000.  ]\n",
            " [ 2813896.6   3290000.  ]\n",
            " [ 4211747.55  4165000.  ]\n",
            " [ 6424730.38  6650000.  ]\n",
            " [ 4215969.75  4165000.  ]\n",
            " [ 5674321.15  4690000.  ]\n",
            " [ 3096921.78  3150000.  ]\n",
            " [ 3316924.95  3850000.  ]\n",
            " [ 3493721.92  3290000.  ]\n",
            " [ 4644389.28  5075000.  ]\n",
            " [ 7047119.07  6510000.  ]\n",
            " [ 4282365.63  5740000.  ]\n",
            " [ 3281115.13  3780000.  ]\n",
            " [ 3953603.07  4795000.  ]\n",
            " [ 4616828.97  4900000.  ]\n",
            " [ 5501570.73  5460000.  ]\n",
            " [ 2965482.47  3500000.  ]\n",
            " [ 7334746.49  7525000.  ]\n",
            " [ 2972943.15  2835000.  ]\n",
            " [ 4357420.48  5495000.  ]\n",
            " [ 7489835.02  8680000.  ]\n",
            " [ 2537363.75  4200000.  ]\n",
            " [ 4553689.25  4200000.  ]\n",
            " [ 4418261.56  4900000.  ]\n",
            " [ 3941488.91  3332000.  ]\n",
            " [ 7511168.9   6195000.  ]\n",
            " [ 4816369.94  4098500.  ]\n",
            " [ 5294430.    6650000.  ]\n",
            " [ 4384634.4   3885000.  ]\n",
            " [ 4245713.66  4620000.  ]\n",
            " [ 3516063.38  1960000.  ]\n",
            " [ 6724922.4   6440000.  ]\n",
            " [ 3289518.79  1750000.  ]\n",
            " [ 4027728.84  3605000.  ]\n",
            " [ 3941488.91  3290000.  ]\n",
            " [ 6152567.19  4970000.  ]\n",
            " [ 4665489.28  4613000.  ]\n",
            " [ 5424615.55  3850000.  ]\n",
            " [ 4124989.44  3500000.  ]\n",
            " [ 4520638.93  6107500.  ]\n",
            " [ 4406372.35  3780000.  ]\n",
            " [ 5491295.98  4900000.  ]\n",
            " [ 4308726.27  3570000.  ]\n",
            " [ 4681333.83  4340000.  ]\n",
            " [ 3516735.5   3500000.  ]\n",
            " [ 6128881.45  6300000.  ]\n",
            " [ 3319477.86  3395000.  ]\n",
            " [ 3462076.59  3815000.  ]\n",
            " [ 3905216.18  3920000.  ]\n",
            " [ 7119137.66 12250000.  ]\n",
            " [ 3470604.31  3080000.  ]\n",
            " [ 8276918.04  9310000.  ]\n",
            " [ 3966060.02  4270000.  ]\n",
            " [ 4046949.54  3780000.  ]\n",
            " [ 6443731.58  5600000.  ]\n",
            " [ 3344687.39  3290000.  ]\n",
            " [ 4345059.33  2380000.  ]\n",
            " [ 3077288.96  5110000.  ]\n",
            " [ 7340772.12  6650000.  ]\n",
            " [ 5171396.28  5810000.  ]\n",
            " [ 4267018.4   4123000.  ]\n",
            " [ 4469414.68  3080000.  ]\n",
            " [ 5855252.94  5530000.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7koIqsoNu4LM",
        "outputId": "b7bac47c-04c0-4503-ff7b-3816d82f5ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6045259725327574"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Regression"
      ],
      "metadata": {
        "id": "5AWHpoMRv-2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor(random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "W_LgPaHCwHBS",
        "outputId": "3648503e-0ac5-4b1a-bd0d-b0dbe90f9f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FbNJuu3lwN8a",
        "outputId": "723f7a8e-568f-4091-9aa0-93e99917e251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4907000.  4585000.]\n",
            " [ 5873000.  6083000.]\n",
            " [ 5145000.  4007500.]\n",
            " [ 5600000.  6930000.]\n",
            " [ 2940000.  2940000.]\n",
            " [ 6650000.  6195000.]\n",
            " [ 3430000.  3535000.]\n",
            " [ 4193000.  2940000.]\n",
            " [ 5250000.  3500000.]\n",
            " [ 6790000.  7980000.]\n",
            " [ 5775000.  6755000.]\n",
            " [ 3500000.  3990000.]\n",
            " [ 4473000.  3150000.]\n",
            " [ 4480000.  3290000.]\n",
            " [ 4480000.  4130000.]\n",
            " [ 2100000.  2660000.]\n",
            " [ 4319000.  4410000.]\n",
            " [ 4480000.  3710000.]\n",
            " [ 3640000.  3360000.]\n",
            " [ 3640000.  4270000.]\n",
            " [ 5250000.  5005000.]\n",
            " [ 9681000.  5383000.]\n",
            " [ 5740000.  6440000.]\n",
            " [ 2100000.  1890000.]\n",
            " [ 6510000.  6125000.]\n",
            " [ 6405000.  5460000.]\n",
            " [ 5229000.  5803000.]\n",
            " [ 5810000.  4620000.]\n",
            " [ 4767000.  5530000.]\n",
            " [ 5110000.  5950000.]\n",
            " [ 3605000.  4305000.]\n",
            " [ 4900000.  3640000.]\n",
            " [ 5950000.  5250000.]\n",
            " [ 3423000.  3325000.]\n",
            " [ 3640000.  3703000.]\n",
            " [ 5950000.  4753000.]\n",
            " [ 6020000.  9100000.]\n",
            " [ 3640000.  3500000.]\n",
            " [ 2660000.  3150000.]\n",
            " [ 4200000.  4270000.]\n",
            " [ 8575000.  8960000.]\n",
            " [ 5250000.  4060000.]\n",
            " [ 5740000.  5740000.]\n",
            " [ 2940000.  3129000.]\n",
            " [ 5250000.  3633000.]\n",
            " [ 6650000.  7560000.]\n",
            " [ 3990000.  4620000.]\n",
            " [ 3423000.  3290000.]\n",
            " [ 4515000.  4165000.]\n",
            " [ 4200000.  6650000.]\n",
            " [ 4403000.  4165000.]\n",
            " [ 5250000.  4690000.]\n",
            " [ 2100000.  3150000.]\n",
            " [ 3710000.  3850000.]\n",
            " [ 3500000.  3290000.]\n",
            " [ 4480000.  5075000.]\n",
            " [ 8043000.  6510000.]\n",
            " [ 4403000.  5740000.]\n",
            " [ 3675000.  3780000.]\n",
            " [ 2940000.  4795000.]\n",
            " [ 3150000.  4900000.]\n",
            " [ 5652500.  5460000.]\n",
            " [ 3885000.  3500000.]\n",
            " [ 7560000.  7525000.]\n",
            " [ 2940000.  2835000.]\n",
            " [ 5110000.  5495000.]\n",
            " [ 9100000.  8680000.]\n",
            " [ 2590000.  4200000.]\n",
            " [ 4060000.  4200000.]\n",
            " [ 5950000.  4900000.]\n",
            " [ 3447500.  3332000.]\n",
            " [ 9800000.  6195000.]\n",
            " [ 4550000.  4098500.]\n",
            " [ 4340000.  6650000.]\n",
            " [ 4445000.  3885000.]\n",
            " [ 4403000.  4620000.]\n",
            " [ 2940000.  1960000.]\n",
            " [10150000.  6440000.]\n",
            " [ 3353000.  1750000.]\n",
            " [ 4830000.  3605000.]\n",
            " [ 3447500.  3290000.]\n",
            " [ 4480000.  4970000.]\n",
            " [ 3850000.  4613000.]\n",
            " [ 5460000.  3850000.]\n",
            " [ 3780000.  3500000.]\n",
            " [ 4900000.  6107500.]\n",
            " [ 6510000.  3780000.]\n",
            " [ 4200000.  4900000.]\n",
            " [ 3640000.  3570000.]\n",
            " [ 4900000.  4340000.]\n",
            " [ 4900000.  3500000.]\n",
            " [ 5215000.  6300000.]\n",
            " [ 3675000.  3395000.]\n",
            " [ 4200000.  3815000.]\n",
            " [ 3430000.  3920000.]\n",
            " [12215000. 12250000.]\n",
            " [ 4550000.  3080000.]\n",
            " [ 5880000.  9310000.]\n",
            " [ 3500000.  4270000.]\n",
            " [ 4550000.  3780000.]\n",
            " [ 9240000.  5600000.]\n",
            " [ 4193000.  3290000.]\n",
            " [ 3885000.  2380000.]\n",
            " [ 1820000.  5110000.]\n",
            " [ 8855000.  6650000.]\n",
            " [ 4620000.  5810000.]\n",
            " [ 2870000.  4123000.]\n",
            " [ 8750000.  3080000.]\n",
            " [ 5950000.  5530000.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ9Tr3F-wPC5",
        "outputId": "078d0f0a-1fb5-4225-9d19-457973a927f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30716046750026493"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Regression"
      ],
      "metadata": {
        "id": "ZqeQrBPpwgYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Xsvdvkv7wih-",
        "outputId": "f3a3b6fa-c54a-419a-86b8-151b28d18ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=10, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NOxFC4WwmAl",
        "outputId": "4c45bf96-72b7-4f1f-a82b-8f6d98b5272b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4369400.  4585000.]\n",
            " [ 6140400.  6083000.]\n",
            " [ 4655000.  4007500.]\n",
            " [ 6605200.  6930000.]\n",
            " [ 3004750.  2940000.]\n",
            " [ 7051800.  6195000.]\n",
            " [ 3146675.  3535000.]\n",
            " [ 3768100.  2940000.]\n",
            " [ 3544800.  3500000.]\n",
            " [ 7602000.  7980000.]\n",
            " [ 6068300.  6755000.]\n",
            " [ 3496500.  3990000.]\n",
            " [ 4378500.  3150000.]\n",
            " [ 5031600.  3290000.]\n",
            " [ 4933600.  4130000.]\n",
            " [ 2187500.  2660000.]\n",
            " [ 4329500.  4410000.]\n",
            " [ 4873400.  3710000.]\n",
            " [ 3479000.  3360000.]\n",
            " [ 3944500.  4270000.]\n",
            " [ 6979000.  5005000.]\n",
            " [ 6568100.  5383000.]\n",
            " [ 4567500.  6440000.]\n",
            " [ 2338000.  1890000.]\n",
            " [ 6215300.  6125000.]\n",
            " [ 4885300.  5460000.]\n",
            " [ 5683300.  5803000.]\n",
            " [ 5257000.  4620000.]\n",
            " [ 4412100.  5530000.]\n",
            " [ 5958400.  5950000.]\n",
            " [ 3628800.  4305000.]\n",
            " [ 5101250.  3640000.]\n",
            " [ 6867000.  5250000.]\n",
            " [ 3229800.  3325000.]\n",
            " [ 5397000.  3703000.]\n",
            " [ 4021500.  4753000.]\n",
            " [ 5910800.  9100000.]\n",
            " [ 3824100.  3500000.]\n",
            " [ 3467800.  3150000.]\n",
            " [ 4088000.  4270000.]\n",
            " [ 8438094.  8960000.]\n",
            " [ 6569500.  4060000.]\n",
            " [ 6543250.  5740000.]\n",
            " [ 3804500.  3129000.]\n",
            " [ 4071200.  3633000.]\n",
            " [ 6613600.  7560000.]\n",
            " [ 4506600.  4620000.]\n",
            " [ 3250100.  3290000.]\n",
            " [ 4712400.  4165000.]\n",
            " [ 4925200.  6650000.]\n",
            " [ 4249700.  4165000.]\n",
            " [ 6881000.  4690000.]\n",
            " [ 2695000.  3150000.]\n",
            " [ 3426500.  3850000.]\n",
            " [ 4798500.  3290000.]\n",
            " [ 4165000.  5075000.]\n",
            " [ 8241800.  6510000.]\n",
            " [ 4027800.  5740000.]\n",
            " [ 3523100.  3780000.]\n",
            " [ 5165300.  4795000.]\n",
            " [ 4491200.  4900000.]\n",
            " [ 6060250.  5460000.]\n",
            " [ 3313800.  3500000.]\n",
            " [ 7437500.  7525000.]\n",
            " [ 3148600.  2835000.]\n",
            " [ 4651500.  5495000.]\n",
            " [ 6748000.  8680000.]\n",
            " [ 2782500.  4200000.]\n",
            " [ 4577300.  4200000.]\n",
            " [ 4784500.  4900000.]\n",
            " [ 3832500.  3332000.]\n",
            " [ 7329000.  6195000.]\n",
            " [ 4507300.  4098500.]\n",
            " [ 4918200.  6650000.]\n",
            " [ 4423300.  3885000.]\n",
            " [ 4058600.  4620000.]\n",
            " [ 3000200.  1960000.]\n",
            " [ 8858500.  6440000.]\n",
            " [ 3076500.  1750000.]\n",
            " [ 4144000.  3605000.]\n",
            " [ 3832500.  3290000.]\n",
            " [ 4982600.  4970000.]\n",
            " [ 4102000.  4613000.]\n",
            " [ 5589500.  3850000.]\n",
            " [ 3945200.  3500000.]\n",
            " [ 3831100.  6107500.]\n",
            " [ 4762800.  3780000.]\n",
            " [ 4720100.  4900000.]\n",
            " [ 3864000.  3570000.]\n",
            " [ 5397000.  4340000.]\n",
            " [ 4534600.  3500000.]\n",
            " [ 5715500.  6300000.]\n",
            " [ 3706500.  3395000.]\n",
            " [ 3339000.  3815000.]\n",
            " [ 3605000.  3920000.]\n",
            " [ 9320500. 12250000.]\n",
            " [ 3405430.  3080000.]\n",
            " [ 7700000.  9310000.]\n",
            " [ 4025000.  4270000.]\n",
            " [ 4936400.  3780000.]\n",
            " [ 9096500.  5600000.]\n",
            " [ 3748500.  3290000.]\n",
            " [ 3980200.  2380000.]\n",
            " [ 2885400.  5110000.]\n",
            " [ 7184800.  6650000.]\n",
            " [ 5264000.  5810000.]\n",
            " [ 4552100.  4123000.]\n",
            " [ 5236000.  3080000.]\n",
            " [ 6835500.  5530000.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F0OlJfwwnRB",
        "outputId": "13c240a0-d34d-4dc2-ac3b-c59bb0645ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.551917541419373"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CatBoost"
      ],
      "metadata": {
        "id": "9qgMuG0Nwx6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "classifier = CatBoostClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o04Sjltw28s",
        "outputId": "b9aee288-fe91-43e9-80a7-b69f652dc26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n",
            "Learning rate set to 0.075847\n",
            "0:\tlearn: 5.2505825\ttotal: 939ms\tremaining: 15m 37s\n",
            "1:\tlearn: 5.2198020\ttotal: 1.34s\tremaining: 11m 9s\n",
            "2:\tlearn: 5.1918582\ttotal: 1.79s\tremaining: 9m 55s\n",
            "3:\tlearn: 5.1602698\ttotal: 2.29s\tremaining: 9m 29s\n",
            "4:\tlearn: 5.1320039\ttotal: 2.59s\tremaining: 8m 35s\n",
            "5:\tlearn: 5.1055793\ttotal: 2.95s\tremaining: 8m 9s\n",
            "6:\tlearn: 5.0776942\ttotal: 3.35s\tremaining: 7m 54s\n",
            "7:\tlearn: 5.0506404\ttotal: 3.74s\tremaining: 7m 44s\n",
            "8:\tlearn: 5.0240562\ttotal: 4.11s\tremaining: 7m 33s\n",
            "9:\tlearn: 4.9966759\ttotal: 4.54s\tremaining: 7m 29s\n",
            "10:\tlearn: 4.9697696\ttotal: 4.87s\tremaining: 7m 18s\n",
            "11:\tlearn: 4.9445003\ttotal: 5.19s\tremaining: 7m 7s\n",
            "12:\tlearn: 4.9177232\ttotal: 5.53s\tremaining: 6m 59s\n",
            "13:\tlearn: 4.8897627\ttotal: 5.88s\tremaining: 6m 54s\n",
            "14:\tlearn: 4.8636742\ttotal: 6.2s\tremaining: 6m 47s\n",
            "15:\tlearn: 4.8367533\ttotal: 6.56s\tremaining: 6m 43s\n",
            "16:\tlearn: 4.8097343\ttotal: 6.83s\tremaining: 6m 34s\n",
            "17:\tlearn: 4.7849557\ttotal: 7.04s\tremaining: 6m 24s\n",
            "18:\tlearn: 4.7589492\ttotal: 7.25s\tremaining: 6m 14s\n",
            "19:\tlearn: 4.7343329\ttotal: 7.48s\tremaining: 6m 6s\n",
            "20:\tlearn: 4.7092360\ttotal: 7.7s\tremaining: 5m 58s\n",
            "21:\tlearn: 4.6828148\ttotal: 7.93s\tremaining: 5m 52s\n",
            "22:\tlearn: 4.6581082\ttotal: 8.14s\tremaining: 5m 45s\n",
            "23:\tlearn: 4.6323115\ttotal: 8.35s\tremaining: 5m 39s\n",
            "24:\tlearn: 4.6079984\ttotal: 8.6s\tremaining: 5m 35s\n",
            "25:\tlearn: 4.5831260\ttotal: 8.84s\tremaining: 5m 31s\n",
            "26:\tlearn: 4.5588092\ttotal: 9.06s\tremaining: 5m 26s\n",
            "27:\tlearn: 4.5331991\ttotal: 9.29s\tremaining: 5m 22s\n",
            "28:\tlearn: 4.5100981\ttotal: 9.5s\tremaining: 5m 17s\n",
            "29:\tlearn: 4.4828634\ttotal: 9.79s\tremaining: 5m 16s\n",
            "30:\tlearn: 4.4579612\ttotal: 10s\tremaining: 5m 13s\n",
            "31:\tlearn: 4.4320158\ttotal: 10.2s\tremaining: 5m 9s\n",
            "32:\tlearn: 4.4096323\ttotal: 10.4s\tremaining: 5m 6s\n",
            "33:\tlearn: 4.3838084\ttotal: 10.7s\tremaining: 5m 4s\n",
            "34:\tlearn: 4.3610169\ttotal: 10.9s\tremaining: 5m 1s\n",
            "35:\tlearn: 4.3370499\ttotal: 11.2s\tremaining: 4m 58s\n",
            "36:\tlearn: 4.3131723\ttotal: 11.4s\tremaining: 4m 56s\n",
            "37:\tlearn: 4.2898688\ttotal: 11.6s\tremaining: 4m 54s\n",
            "38:\tlearn: 4.2677877\ttotal: 11.9s\tremaining: 4m 52s\n",
            "39:\tlearn: 4.2440293\ttotal: 12.1s\tremaining: 4m 50s\n",
            "40:\tlearn: 4.2206024\ttotal: 12.4s\tremaining: 4m 48s\n",
            "41:\tlearn: 4.1987002\ttotal: 12.7s\tremaining: 4m 49s\n",
            "42:\tlearn: 4.1765523\ttotal: 13.1s\tremaining: 4m 50s\n",
            "43:\tlearn: 4.1535664\ttotal: 13.4s\tremaining: 4m 51s\n",
            "44:\tlearn: 4.1304998\ttotal: 13.8s\tremaining: 4m 53s\n",
            "45:\tlearn: 4.1086049\ttotal: 14.2s\tremaining: 4m 53s\n",
            "46:\tlearn: 4.0860174\ttotal: 14.5s\tremaining: 4m 54s\n",
            "47:\tlearn: 4.0627539\ttotal: 14.9s\tremaining: 4m 55s\n",
            "48:\tlearn: 4.0413992\ttotal: 15.3s\tremaining: 4m 56s\n",
            "49:\tlearn: 4.0189907\ttotal: 15.7s\tremaining: 4m 57s\n",
            "50:\tlearn: 3.9986296\ttotal: 16s\tremaining: 4m 58s\n",
            "51:\tlearn: 3.9768133\ttotal: 16.4s\tremaining: 4m 58s\n",
            "52:\tlearn: 3.9560102\ttotal: 16.6s\tremaining: 4m 56s\n",
            "53:\tlearn: 3.9359104\ttotal: 16.8s\tremaining: 4m 54s\n",
            "54:\tlearn: 3.9157932\ttotal: 17s\tremaining: 4m 52s\n",
            "55:\tlearn: 3.8959292\ttotal: 17.3s\tremaining: 4m 50s\n",
            "56:\tlearn: 3.8752609\ttotal: 17.5s\tremaining: 4m 48s\n",
            "57:\tlearn: 3.8542469\ttotal: 17.7s\tremaining: 4m 47s\n",
            "58:\tlearn: 3.8332412\ttotal: 17.9s\tremaining: 4m 45s\n",
            "59:\tlearn: 3.8113118\ttotal: 18.1s\tremaining: 4m 44s\n",
            "60:\tlearn: 3.7892406\ttotal: 18.4s\tremaining: 4m 42s\n",
            "61:\tlearn: 3.7694249\ttotal: 18.6s\tremaining: 4m 41s\n",
            "62:\tlearn: 3.7504015\ttotal: 18.8s\tremaining: 4m 39s\n",
            "63:\tlearn: 3.7314914\ttotal: 19s\tremaining: 4m 38s\n",
            "64:\tlearn: 3.7121084\ttotal: 19.2s\tremaining: 4m 36s\n",
            "65:\tlearn: 3.7030990\ttotal: 19.2s\tremaining: 4m 32s\n",
            "66:\tlearn: 3.6839127\ttotal: 19.5s\tremaining: 4m 30s\n",
            "67:\tlearn: 3.6638359\ttotal: 19.7s\tremaining: 4m 29s\n",
            "68:\tlearn: 3.6452193\ttotal: 19.9s\tremaining: 4m 28s\n",
            "69:\tlearn: 3.6258789\ttotal: 20.1s\tremaining: 4m 26s\n",
            "70:\tlearn: 3.6080029\ttotal: 20.3s\tremaining: 4m 25s\n",
            "71:\tlearn: 3.5906015\ttotal: 20.5s\tremaining: 4m 24s\n",
            "72:\tlearn: 3.5718578\ttotal: 20.7s\tremaining: 4m 23s\n",
            "73:\tlearn: 3.5537095\ttotal: 20.9s\tremaining: 4m 21s\n",
            "74:\tlearn: 3.5362366\ttotal: 21.1s\tremaining: 4m 20s\n",
            "75:\tlearn: 3.5167237\ttotal: 21.4s\tremaining: 4m 19s\n",
            "76:\tlearn: 3.4982786\ttotal: 21.6s\tremaining: 4m 18s\n",
            "77:\tlearn: 3.4789773\ttotal: 21.8s\tremaining: 4m 17s\n",
            "78:\tlearn: 3.4599599\ttotal: 22s\tremaining: 4m 16s\n",
            "79:\tlearn: 3.4408320\ttotal: 22.3s\tremaining: 4m 16s\n",
            "80:\tlearn: 3.4216085\ttotal: 22.5s\tremaining: 4m 15s\n",
            "81:\tlearn: 3.4036104\ttotal: 22.7s\tremaining: 4m 14s\n",
            "82:\tlearn: 3.3845795\ttotal: 23s\tremaining: 4m 13s\n",
            "83:\tlearn: 3.3655987\ttotal: 23.2s\tremaining: 4m 12s\n",
            "84:\tlearn: 3.3474145\ttotal: 23.4s\tremaining: 4m 12s\n",
            "85:\tlearn: 3.3272094\ttotal: 23.6s\tremaining: 4m 11s\n",
            "86:\tlearn: 3.3074844\ttotal: 23.9s\tremaining: 4m 10s\n",
            "87:\tlearn: 3.2898092\ttotal: 24.1s\tremaining: 4m 9s\n",
            "88:\tlearn: 3.2719671\ttotal: 24.3s\tremaining: 4m 8s\n",
            "89:\tlearn: 3.2546847\ttotal: 24.5s\tremaining: 4m 8s\n",
            "90:\tlearn: 3.2388844\ttotal: 24.7s\tremaining: 4m 7s\n",
            "91:\tlearn: 3.2210929\ttotal: 25s\tremaining: 4m 6s\n",
            "92:\tlearn: 3.2037033\ttotal: 25.2s\tremaining: 4m 5s\n",
            "93:\tlearn: 3.1867431\ttotal: 25.4s\tremaining: 4m 4s\n",
            "94:\tlearn: 3.1702022\ttotal: 25.6s\tremaining: 4m 4s\n",
            "95:\tlearn: 3.1528196\ttotal: 25.9s\tremaining: 4m 3s\n",
            "96:\tlearn: 3.1360363\ttotal: 26.1s\tremaining: 4m 2s\n",
            "97:\tlearn: 3.1195560\ttotal: 26.3s\tremaining: 4m 2s\n",
            "98:\tlearn: 3.1027013\ttotal: 26.6s\tremaining: 4m 2s\n",
            "99:\tlearn: 3.0846251\ttotal: 27s\tremaining: 4m 2s\n",
            "100:\tlearn: 3.0680352\ttotal: 27.3s\tremaining: 4m 3s\n",
            "101:\tlearn: 3.0520160\ttotal: 27.7s\tremaining: 4m 3s\n",
            "102:\tlearn: 3.0350948\ttotal: 28s\tremaining: 4m 4s\n",
            "103:\tlearn: 3.0192598\ttotal: 28.4s\tremaining: 4m 4s\n",
            "104:\tlearn: 3.0013373\ttotal: 28.7s\tremaining: 4m 5s\n",
            "105:\tlearn: 2.9835457\ttotal: 29.1s\tremaining: 4m 5s\n",
            "106:\tlearn: 2.9672658\ttotal: 29.5s\tremaining: 4m 6s\n",
            "107:\tlearn: 2.9507325\ttotal: 29.9s\tremaining: 4m 6s\n",
            "108:\tlearn: 2.9344861\ttotal: 30.2s\tremaining: 4m 7s\n",
            "109:\tlearn: 2.9172662\ttotal: 30.5s\tremaining: 4m 6s\n",
            "110:\tlearn: 2.9014742\ttotal: 30.7s\tremaining: 4m 5s\n",
            "111:\tlearn: 2.8852864\ttotal: 30.9s\tremaining: 4m 5s\n",
            "112:\tlearn: 2.8690177\ttotal: 31.1s\tremaining: 4m 4s\n",
            "113:\tlearn: 2.8539497\ttotal: 31.4s\tremaining: 4m 3s\n",
            "114:\tlearn: 2.8372487\ttotal: 31.6s\tremaining: 4m 3s\n",
            "115:\tlearn: 2.8206724\ttotal: 31.8s\tremaining: 4m 2s\n",
            "116:\tlearn: 2.8049678\ttotal: 32s\tremaining: 4m 1s\n",
            "117:\tlearn: 2.7908448\ttotal: 32.2s\tremaining: 4m 1s\n",
            "118:\tlearn: 2.7753450\ttotal: 32.5s\tremaining: 4m\n",
            "119:\tlearn: 2.7605148\ttotal: 32.7s\tremaining: 3m 59s\n",
            "120:\tlearn: 2.7479703\ttotal: 32.9s\tremaining: 3m 58s\n",
            "121:\tlearn: 2.7341803\ttotal: 33.1s\tremaining: 3m 58s\n",
            "122:\tlearn: 2.7188186\ttotal: 33.3s\tremaining: 3m 57s\n",
            "123:\tlearn: 2.7047460\ttotal: 33.5s\tremaining: 3m 56s\n",
            "124:\tlearn: 2.6888910\ttotal: 33.8s\tremaining: 3m 56s\n",
            "125:\tlearn: 2.6780939\ttotal: 34s\tremaining: 3m 55s\n",
            "126:\tlearn: 2.6637064\ttotal: 34.2s\tremaining: 3m 55s\n",
            "127:\tlearn: 2.6490145\ttotal: 34.4s\tremaining: 3m 54s\n",
            "128:\tlearn: 2.6343099\ttotal: 34.6s\tremaining: 3m 53s\n",
            "129:\tlearn: 2.6225329\ttotal: 34.9s\tremaining: 3m 53s\n",
            "130:\tlearn: 2.6073497\ttotal: 35.1s\tremaining: 3m 52s\n",
            "131:\tlearn: 2.5925063\ttotal: 35.3s\tremaining: 3m 51s\n",
            "132:\tlearn: 2.5794097\ttotal: 35.5s\tremaining: 3m 51s\n",
            "133:\tlearn: 2.5659531\ttotal: 35.7s\tremaining: 3m 50s\n",
            "134:\tlearn: 2.5508625\ttotal: 36s\tremaining: 3m 50s\n",
            "135:\tlearn: 2.5366895\ttotal: 36.2s\tremaining: 3m 49s\n",
            "136:\tlearn: 2.5215832\ttotal: 36.4s\tremaining: 3m 49s\n",
            "137:\tlearn: 2.5101441\ttotal: 36.6s\tremaining: 3m 48s\n",
            "138:\tlearn: 2.4969188\ttotal: 36.8s\tremaining: 3m 48s\n",
            "139:\tlearn: 2.4839790\ttotal: 37s\tremaining: 3m 47s\n",
            "140:\tlearn: 2.4705283\ttotal: 37.3s\tremaining: 3m 47s\n",
            "141:\tlearn: 2.4572029\ttotal: 37.5s\tremaining: 3m 46s\n",
            "142:\tlearn: 2.4461598\ttotal: 37.7s\tremaining: 3m 46s\n",
            "143:\tlearn: 2.4337515\ttotal: 37.9s\tremaining: 3m 45s\n",
            "144:\tlearn: 2.4194145\ttotal: 38.2s\tremaining: 3m 45s\n",
            "145:\tlearn: 2.4065096\ttotal: 38.4s\tremaining: 3m 44s\n",
            "146:\tlearn: 2.3967699\ttotal: 38.6s\tremaining: 3m 43s\n",
            "147:\tlearn: 2.3851322\ttotal: 38.8s\tremaining: 3m 43s\n",
            "148:\tlearn: 2.3738451\ttotal: 39s\tremaining: 3m 42s\n",
            "149:\tlearn: 2.3615391\ttotal: 39.2s\tremaining: 3m 42s\n",
            "150:\tlearn: 2.3486443\ttotal: 39.5s\tremaining: 3m 41s\n",
            "151:\tlearn: 2.3377681\ttotal: 39.7s\tremaining: 3m 41s\n",
            "152:\tlearn: 2.3231866\ttotal: 40s\tremaining: 3m 41s\n",
            "153:\tlearn: 2.3123457\ttotal: 40.2s\tremaining: 3m 40s\n",
            "154:\tlearn: 2.2991389\ttotal: 40.5s\tremaining: 3m 40s\n",
            "155:\tlearn: 2.2859988\ttotal: 40.8s\tremaining: 3m 40s\n",
            "156:\tlearn: 2.2751321\ttotal: 41.2s\tremaining: 3m 41s\n",
            "157:\tlearn: 2.2645710\ttotal: 41.5s\tremaining: 3m 41s\n",
            "158:\tlearn: 2.2537649\ttotal: 41.9s\tremaining: 3m 41s\n",
            "159:\tlearn: 2.2418223\ttotal: 42.2s\tremaining: 3m 41s\n",
            "160:\tlearn: 2.2297449\ttotal: 42.6s\tremaining: 3m 41s\n",
            "161:\tlearn: 2.2163804\ttotal: 43s\tremaining: 3m 42s\n",
            "162:\tlearn: 2.2032790\ttotal: 43.3s\tremaining: 3m 42s\n",
            "163:\tlearn: 2.1923111\ttotal: 43.7s\tremaining: 3m 42s\n",
            "164:\tlearn: 2.1804111\ttotal: 44s\tremaining: 3m 42s\n",
            "165:\tlearn: 2.1689142\ttotal: 44.4s\tremaining: 3m 42s\n",
            "166:\tlearn: 2.1564451\ttotal: 44.6s\tremaining: 3m 42s\n",
            "167:\tlearn: 2.1470916\ttotal: 44.8s\tremaining: 3m 41s\n",
            "168:\tlearn: 2.1360253\ttotal: 45s\tremaining: 3m 41s\n",
            "169:\tlearn: 2.1236160\ttotal: 45.2s\tremaining: 3m 40s\n",
            "170:\tlearn: 2.1136549\ttotal: 45.5s\tremaining: 3m 40s\n",
            "171:\tlearn: 2.1027402\ttotal: 45.7s\tremaining: 3m 39s\n",
            "172:\tlearn: 2.0927830\ttotal: 45.9s\tremaining: 3m 39s\n",
            "173:\tlearn: 2.0878095\ttotal: 46.1s\tremaining: 3m 38s\n",
            "174:\tlearn: 2.0777402\ttotal: 46.3s\tremaining: 3m 38s\n",
            "175:\tlearn: 2.0661082\ttotal: 46.6s\tremaining: 3m 37s\n",
            "176:\tlearn: 2.0567368\ttotal: 46.8s\tremaining: 3m 37s\n",
            "177:\tlearn: 2.0451502\ttotal: 47s\tremaining: 3m 36s\n",
            "178:\tlearn: 2.0342526\ttotal: 47.2s\tremaining: 3m 36s\n",
            "179:\tlearn: 2.0238519\ttotal: 47.4s\tremaining: 3m 36s\n",
            "180:\tlearn: 2.0139564\ttotal: 47.7s\tremaining: 3m 35s\n",
            "181:\tlearn: 2.0019367\ttotal: 47.9s\tremaining: 3m 35s\n",
            "182:\tlearn: 1.9925603\ttotal: 48.1s\tremaining: 3m 34s\n",
            "183:\tlearn: 1.9857514\ttotal: 48.3s\tremaining: 3m 34s\n",
            "184:\tlearn: 1.9735789\ttotal: 48.6s\tremaining: 3m 34s\n",
            "185:\tlearn: 1.9641129\ttotal: 48.8s\tremaining: 3m 33s\n",
            "186:\tlearn: 1.9548805\ttotal: 49s\tremaining: 3m 33s\n",
            "187:\tlearn: 1.9443339\ttotal: 49.2s\tremaining: 3m 32s\n",
            "188:\tlearn: 1.9339740\ttotal: 49.5s\tremaining: 3m 32s\n",
            "189:\tlearn: 1.9254589\ttotal: 49.7s\tremaining: 3m 31s\n",
            "190:\tlearn: 1.9163882\ttotal: 49.9s\tremaining: 3m 31s\n",
            "191:\tlearn: 1.9062242\ttotal: 50.1s\tremaining: 3m 30s\n",
            "192:\tlearn: 1.8945546\ttotal: 50.3s\tremaining: 3m 30s\n",
            "193:\tlearn: 1.8840687\ttotal: 50.6s\tremaining: 3m 30s\n",
            "194:\tlearn: 1.8739791\ttotal: 50.8s\tremaining: 3m 29s\n",
            "195:\tlearn: 1.8638964\ttotal: 51s\tremaining: 3m 29s\n",
            "196:\tlearn: 1.8542887\ttotal: 51.2s\tremaining: 3m 28s\n",
            "197:\tlearn: 1.8449132\ttotal: 51.4s\tremaining: 3m 28s\n",
            "198:\tlearn: 1.8360048\ttotal: 51.7s\tremaining: 3m 28s\n",
            "199:\tlearn: 1.8253164\ttotal: 51.9s\tremaining: 3m 27s\n",
            "200:\tlearn: 1.8153343\ttotal: 52.1s\tremaining: 3m 27s\n",
            "201:\tlearn: 1.8065342\ttotal: 52.3s\tremaining: 3m 26s\n",
            "202:\tlearn: 1.7967013\ttotal: 52.6s\tremaining: 3m 26s\n",
            "203:\tlearn: 1.7859021\ttotal: 52.8s\tremaining: 3m 26s\n",
            "204:\tlearn: 1.7762512\ttotal: 53s\tremaining: 3m 25s\n",
            "205:\tlearn: 1.7697033\ttotal: 53.2s\tremaining: 3m 25s\n",
            "206:\tlearn: 1.7603208\ttotal: 53.5s\tremaining: 3m 24s\n",
            "207:\tlearn: 1.7529171\ttotal: 53.7s\tremaining: 3m 24s\n",
            "208:\tlearn: 1.7444289\ttotal: 53.9s\tremaining: 3m 24s\n",
            "209:\tlearn: 1.7369818\ttotal: 54.1s\tremaining: 3m 23s\n",
            "210:\tlearn: 1.7295219\ttotal: 54.3s\tremaining: 3m 23s\n",
            "211:\tlearn: 1.7191333\ttotal: 54.7s\tremaining: 3m 23s\n",
            "212:\tlearn: 1.7091969\ttotal: 55.1s\tremaining: 3m 23s\n",
            "213:\tlearn: 1.7007657\ttotal: 55.4s\tremaining: 3m 23s\n",
            "214:\tlearn: 1.6939072\ttotal: 55.8s\tremaining: 3m 23s\n",
            "215:\tlearn: 1.6855449\ttotal: 56.1s\tremaining: 3m 23s\n",
            "216:\tlearn: 1.6777545\ttotal: 56.5s\tremaining: 3m 23s\n",
            "217:\tlearn: 1.6693558\ttotal: 56.8s\tremaining: 3m 23s\n",
            "218:\tlearn: 1.6604325\ttotal: 57.2s\tremaining: 3m 23s\n",
            "219:\tlearn: 1.6531537\ttotal: 57.5s\tremaining: 3m 23s\n",
            "220:\tlearn: 1.6455822\ttotal: 57.9s\tremaining: 3m 23s\n",
            "221:\tlearn: 1.6371094\ttotal: 58.2s\tremaining: 3m 23s\n",
            "222:\tlearn: 1.6290685\ttotal: 58.4s\tremaining: 3m 23s\n",
            "223:\tlearn: 1.6210580\ttotal: 58.6s\tremaining: 3m 23s\n",
            "224:\tlearn: 1.6126138\ttotal: 58.8s\tremaining: 3m 22s\n",
            "225:\tlearn: 1.6038773\ttotal: 59.1s\tremaining: 3m 22s\n",
            "226:\tlearn: 1.5964975\ttotal: 59.3s\tremaining: 3m 21s\n",
            "227:\tlearn: 1.5901522\ttotal: 59.5s\tremaining: 3m 21s\n",
            "228:\tlearn: 1.5828304\ttotal: 59.7s\tremaining: 3m 20s\n",
            "229:\tlearn: 1.5740674\ttotal: 59.9s\tremaining: 3m 20s\n",
            "230:\tlearn: 1.5675992\ttotal: 1m\tremaining: 3m 20s\n",
            "231:\tlearn: 1.5641640\ttotal: 1m\tremaining: 3m 19s\n",
            "232:\tlearn: 1.5566697\ttotal: 1m\tremaining: 3m 19s\n",
            "233:\tlearn: 1.5492376\ttotal: 1m\tremaining: 3m 18s\n",
            "234:\tlearn: 1.5416530\ttotal: 1m\tremaining: 3m 18s\n",
            "235:\tlearn: 1.5337557\ttotal: 1m 1s\tremaining: 3m 18s\n",
            "236:\tlearn: 1.5258657\ttotal: 1m 1s\tremaining: 3m 17s\n",
            "237:\tlearn: 1.5179417\ttotal: 1m 1s\tremaining: 3m 17s\n",
            "238:\tlearn: 1.5112251\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "239:\tlearn: 1.5067672\ttotal: 1m 2s\tremaining: 3m 16s\n",
            "240:\tlearn: 1.4999647\ttotal: 1m 2s\tremaining: 3m 16s\n",
            "241:\tlearn: 1.4930339\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "242:\tlearn: 1.4870319\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "243:\tlearn: 1.4815313\ttotal: 1m 2s\tremaining: 3m 14s\n",
            "244:\tlearn: 1.4740625\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "245:\tlearn: 1.4689037\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "246:\tlearn: 1.4621433\ttotal: 1m 3s\tremaining: 3m 13s\n",
            "247:\tlearn: 1.4568351\ttotal: 1m 3s\tremaining: 3m 13s\n",
            "248:\tlearn: 1.4505586\ttotal: 1m 3s\tremaining: 3m 12s\n",
            "249:\tlearn: 1.4446132\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "250:\tlearn: 1.4375589\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "251:\tlearn: 1.4297793\ttotal: 1m 4s\tremaining: 3m 11s\n",
            "252:\tlearn: 1.4235423\ttotal: 1m 4s\tremaining: 3m 11s\n",
            "253:\tlearn: 1.4172496\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "254:\tlearn: 1.4105423\ttotal: 1m 5s\tremaining: 3m 10s\n",
            "255:\tlearn: 1.4050409\ttotal: 1m 5s\tremaining: 3m 10s\n",
            "256:\tlearn: 1.3989623\ttotal: 1m 5s\tremaining: 3m 9s\n",
            "257:\tlearn: 1.3915883\ttotal: 1m 5s\tremaining: 3m 9s\n",
            "258:\tlearn: 1.3849875\ttotal: 1m 6s\tremaining: 3m 9s\n",
            "259:\tlearn: 1.3792712\ttotal: 1m 6s\tremaining: 3m 8s\n",
            "260:\tlearn: 1.3727370\ttotal: 1m 6s\tremaining: 3m 8s\n",
            "261:\tlearn: 1.3666988\ttotal: 1m 6s\tremaining: 3m 8s\n",
            "262:\tlearn: 1.3598857\ttotal: 1m 7s\tremaining: 3m 7s\n",
            "263:\tlearn: 1.3527336\ttotal: 1m 7s\tremaining: 3m 7s\n",
            "264:\tlearn: 1.3472862\ttotal: 1m 7s\tremaining: 3m 7s\n",
            "265:\tlearn: 1.3413825\ttotal: 1m 7s\tremaining: 3m 6s\n",
            "266:\tlearn: 1.3363352\ttotal: 1m 7s\tremaining: 3m 6s\n",
            "267:\tlearn: 1.3300884\ttotal: 1m 8s\tremaining: 3m 6s\n",
            "268:\tlearn: 1.3237534\ttotal: 1m 8s\tremaining: 3m 5s\n",
            "269:\tlearn: 1.3188484\ttotal: 1m 8s\tremaining: 3m 5s\n",
            "270:\tlearn: 1.3125600\ttotal: 1m 9s\tremaining: 3m 5s\n",
            "271:\tlearn: 1.3086096\ttotal: 1m 9s\tremaining: 3m 5s\n",
            "272:\tlearn: 1.3022584\ttotal: 1m 9s\tremaining: 3m 5s\n",
            "273:\tlearn: 1.2969038\ttotal: 1m 10s\tremaining: 3m 5s\n",
            "274:\tlearn: 1.2923753\ttotal: 1m 10s\tremaining: 3m 5s\n",
            "275:\tlearn: 1.2866660\ttotal: 1m 10s\tremaining: 3m 5s\n",
            "276:\tlearn: 1.2819781\ttotal: 1m 11s\tremaining: 3m 5s\n",
            "277:\tlearn: 1.2760054\ttotal: 1m 11s\tremaining: 3m 5s\n",
            "278:\tlearn: 1.2709102\ttotal: 1m 11s\tremaining: 3m 5s\n",
            "279:\tlearn: 1.2661809\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "280:\tlearn: 1.2604571\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "281:\tlearn: 1.2584698\ttotal: 1m 12s\tremaining: 3m 4s\n",
            "282:\tlearn: 1.2531132\ttotal: 1m 12s\tremaining: 3m 4s\n",
            "283:\tlearn: 1.2490412\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "284:\tlearn: 1.2450648\ttotal: 1m 13s\tremaining: 3m 3s\n",
            "285:\tlearn: 1.2406259\ttotal: 1m 13s\tremaining: 3m 3s\n",
            "286:\tlearn: 1.2347890\ttotal: 1m 13s\tremaining: 3m 3s\n",
            "287:\tlearn: 1.2300453\ttotal: 1m 13s\tremaining: 3m 2s\n",
            "288:\tlearn: 1.2267409\ttotal: 1m 14s\tremaining: 3m 2s\n",
            "289:\tlearn: 1.2213790\ttotal: 1m 14s\tremaining: 3m 2s\n",
            "290:\tlearn: 1.2150649\ttotal: 1m 14s\tremaining: 3m 1s\n",
            "291:\tlearn: 1.2106191\ttotal: 1m 14s\tremaining: 3m 1s\n",
            "292:\tlearn: 1.2049251\ttotal: 1m 15s\tremaining: 3m 1s\n",
            "293:\tlearn: 1.2004976\ttotal: 1m 15s\tremaining: 3m\n",
            "294:\tlearn: 1.1957731\ttotal: 1m 15s\tremaining: 3m\n",
            "295:\tlearn: 1.1904549\ttotal: 1m 15s\tremaining: 3m\n",
            "296:\tlearn: 1.1843213\ttotal: 1m 15s\tremaining: 2m 59s\n",
            "297:\tlearn: 1.1792756\ttotal: 1m 16s\tremaining: 2m 59s\n",
            "298:\tlearn: 1.1746495\ttotal: 1m 16s\tremaining: 2m 59s\n",
            "299:\tlearn: 1.1696995\ttotal: 1m 16s\tremaining: 2m 58s\n",
            "300:\tlearn: 1.1655726\ttotal: 1m 16s\tremaining: 2m 58s\n",
            "301:\tlearn: 1.1620878\ttotal: 1m 17s\tremaining: 2m 58s\n",
            "302:\tlearn: 1.1579555\ttotal: 1m 17s\tremaining: 2m 57s\n",
            "303:\tlearn: 1.1551056\ttotal: 1m 17s\tremaining: 2m 57s\n",
            "304:\tlearn: 1.1506019\ttotal: 1m 17s\tremaining: 2m 56s\n",
            "305:\tlearn: 1.1456440\ttotal: 1m 17s\tremaining: 2m 56s\n",
            "306:\tlearn: 1.1409620\ttotal: 1m 18s\tremaining: 2m 56s\n",
            "307:\tlearn: 1.1360705\ttotal: 1m 18s\tremaining: 2m 55s\n",
            "308:\tlearn: 1.1320907\ttotal: 1m 18s\tremaining: 2m 55s\n",
            "309:\tlearn: 1.1278662\ttotal: 1m 18s\tremaining: 2m 55s\n",
            "310:\tlearn: 1.1232154\ttotal: 1m 18s\tremaining: 2m 54s\n",
            "311:\tlearn: 1.1193585\ttotal: 1m 19s\tremaining: 2m 54s\n",
            "312:\tlearn: 1.1152728\ttotal: 1m 19s\tremaining: 2m 54s\n",
            "313:\tlearn: 1.1104492\ttotal: 1m 19s\tremaining: 2m 53s\n",
            "314:\tlearn: 1.1067872\ttotal: 1m 19s\tremaining: 2m 53s\n",
            "315:\tlearn: 1.1026560\ttotal: 1m 19s\tremaining: 2m 53s\n",
            "316:\tlearn: 1.0980376\ttotal: 1m 20s\tremaining: 2m 52s\n",
            "317:\tlearn: 1.0942357\ttotal: 1m 20s\tremaining: 2m 52s\n",
            "318:\tlearn: 1.0889915\ttotal: 1m 20s\tremaining: 2m 52s\n",
            "319:\tlearn: 1.0853266\ttotal: 1m 20s\tremaining: 2m 51s\n",
            "320:\tlearn: 1.0827995\ttotal: 1m 21s\tremaining: 2m 51s\n",
            "321:\tlearn: 1.0793679\ttotal: 1m 21s\tremaining: 2m 51s\n",
            "322:\tlearn: 1.0752487\ttotal: 1m 21s\tremaining: 2m 50s\n",
            "323:\tlearn: 1.0710849\ttotal: 1m 21s\tremaining: 2m 50s\n",
            "324:\tlearn: 1.0665712\ttotal: 1m 21s\tremaining: 2m 50s\n",
            "325:\tlearn: 1.0632298\ttotal: 1m 22s\tremaining: 2m 49s\n",
            "326:\tlearn: 1.0592157\ttotal: 1m 22s\tremaining: 2m 49s\n",
            "327:\tlearn: 1.0559493\ttotal: 1m 22s\tremaining: 2m 49s\n",
            "328:\tlearn: 1.0518743\ttotal: 1m 23s\tremaining: 2m 49s\n",
            "329:\tlearn: 1.0472791\ttotal: 1m 23s\tremaining: 2m 49s\n",
            "330:\tlearn: 1.0432443\ttotal: 1m 23s\tremaining: 2m 49s\n",
            "331:\tlearn: 1.0388447\ttotal: 1m 24s\tremaining: 2m 49s\n",
            "332:\tlearn: 1.0345671\ttotal: 1m 24s\tremaining: 2m 49s\n",
            "333:\tlearn: 1.0313188\ttotal: 1m 25s\tremaining: 2m 49s\n",
            "334:\tlearn: 1.0268493\ttotal: 1m 25s\tremaining: 2m 49s\n",
            "335:\tlearn: 1.0234408\ttotal: 1m 25s\tremaining: 2m 49s\n",
            "336:\tlearn: 1.0195109\ttotal: 1m 26s\tremaining: 2m 49s\n",
            "337:\tlearn: 1.0157157\ttotal: 1m 26s\tremaining: 2m 49s\n",
            "338:\tlearn: 1.0127533\ttotal: 1m 26s\tremaining: 2m 48s\n",
            "339:\tlearn: 1.0089997\ttotal: 1m 26s\tremaining: 2m 48s\n",
            "340:\tlearn: 1.0053491\ttotal: 1m 26s\tremaining: 2m 47s\n",
            "341:\tlearn: 1.0022237\ttotal: 1m 27s\tremaining: 2m 47s\n",
            "342:\tlearn: 0.9987398\ttotal: 1m 27s\tremaining: 2m 47s\n",
            "343:\tlearn: 0.9945209\ttotal: 1m 27s\tremaining: 2m 47s\n",
            "344:\tlearn: 0.9909646\ttotal: 1m 27s\tremaining: 2m 46s\n",
            "345:\tlearn: 0.9875162\ttotal: 1m 28s\tremaining: 2m 46s\n",
            "346:\tlearn: 0.9833436\ttotal: 1m 28s\tremaining: 2m 46s\n",
            "347:\tlearn: 0.9793031\ttotal: 1m 28s\tremaining: 2m 45s\n",
            "348:\tlearn: 0.9761394\ttotal: 1m 28s\tremaining: 2m 45s\n",
            "349:\tlearn: 0.9723270\ttotal: 1m 28s\tremaining: 2m 45s\n",
            "350:\tlearn: 0.9688707\ttotal: 1m 29s\tremaining: 2m 44s\n",
            "351:\tlearn: 0.9659004\ttotal: 1m 29s\tremaining: 2m 44s\n",
            "352:\tlearn: 0.9622758\ttotal: 1m 29s\tremaining: 2m 44s\n",
            "353:\tlearn: 0.9588833\ttotal: 1m 29s\tremaining: 2m 43s\n",
            "354:\tlearn: 0.9562533\ttotal: 1m 29s\tremaining: 2m 43s\n",
            "355:\tlearn: 0.9534022\ttotal: 1m 30s\tremaining: 2m 43s\n",
            "356:\tlearn: 0.9512410\ttotal: 1m 30s\tremaining: 2m 42s\n",
            "357:\tlearn: 0.9484921\ttotal: 1m 30s\tremaining: 2m 42s\n",
            "358:\tlearn: 0.9454951\ttotal: 1m 30s\tremaining: 2m 42s\n",
            "359:\tlearn: 0.9418798\ttotal: 1m 31s\tremaining: 2m 41s\n",
            "360:\tlearn: 0.9389070\ttotal: 1m 31s\tremaining: 2m 41s\n",
            "361:\tlearn: 0.9367763\ttotal: 1m 31s\tremaining: 2m 41s\n",
            "362:\tlearn: 0.9330464\ttotal: 1m 31s\tremaining: 2m 40s\n",
            "363:\tlearn: 0.9294646\ttotal: 1m 31s\tremaining: 2m 40s\n",
            "364:\tlearn: 0.9272131\ttotal: 1m 32s\tremaining: 2m 40s\n",
            "365:\tlearn: 0.9234868\ttotal: 1m 32s\tremaining: 2m 39s\n",
            "366:\tlearn: 0.9203428\ttotal: 1m 32s\tremaining: 2m 39s\n",
            "367:\tlearn: 0.9179453\ttotal: 1m 32s\tremaining: 2m 39s\n",
            "368:\tlearn: 0.9163365\ttotal: 1m 32s\tremaining: 2m 39s\n",
            "369:\tlearn: 0.9134135\ttotal: 1m 33s\tremaining: 2m 38s\n",
            "370:\tlearn: 0.9098514\ttotal: 1m 33s\tremaining: 2m 38s\n",
            "371:\tlearn: 0.9070728\ttotal: 1m 33s\tremaining: 2m 38s\n",
            "372:\tlearn: 0.9049165\ttotal: 1m 33s\tremaining: 2m 37s\n",
            "373:\tlearn: 0.9016860\ttotal: 1m 34s\tremaining: 2m 37s\n",
            "374:\tlearn: 0.8984316\ttotal: 1m 34s\tremaining: 2m 37s\n",
            "375:\tlearn: 0.8950609\ttotal: 1m 34s\tremaining: 2m 36s\n",
            "376:\tlearn: 0.8918105\ttotal: 1m 34s\tremaining: 2m 36s\n",
            "377:\tlearn: 0.8892994\ttotal: 1m 34s\tremaining: 2m 36s\n",
            "378:\tlearn: 0.8865016\ttotal: 1m 35s\tremaining: 2m 35s\n",
            "379:\tlearn: 0.8838297\ttotal: 1m 35s\tremaining: 2m 35s\n",
            "380:\tlearn: 0.8805076\ttotal: 1m 35s\tremaining: 2m 35s\n",
            "381:\tlearn: 0.8792246\ttotal: 1m 35s\tremaining: 2m 34s\n",
            "382:\tlearn: 0.8767468\ttotal: 1m 36s\tremaining: 2m 34s\n",
            "383:\tlearn: 0.8737021\ttotal: 1m 36s\tremaining: 2m 34s\n",
            "384:\tlearn: 0.8722206\ttotal: 1m 36s\tremaining: 2m 34s\n",
            "385:\tlearn: 0.8692355\ttotal: 1m 37s\tremaining: 2m 34s\n",
            "386:\tlearn: 0.8661997\ttotal: 1m 37s\tremaining: 2m 34s\n",
            "387:\tlearn: 0.8645665\ttotal: 1m 37s\tremaining: 2m 34s\n",
            "388:\tlearn: 0.8619521\ttotal: 1m 38s\tremaining: 2m 33s\n",
            "389:\tlearn: 0.8592629\ttotal: 1m 38s\tremaining: 2m 33s\n",
            "390:\tlearn: 0.8576962\ttotal: 1m 38s\tremaining: 2m 33s\n",
            "391:\tlearn: 0.8559436\ttotal: 1m 39s\tremaining: 2m 33s\n",
            "392:\tlearn: 0.8530146\ttotal: 1m 39s\tremaining: 2m 33s\n",
            "393:\tlearn: 0.8497338\ttotal: 1m 39s\tremaining: 2m 33s\n",
            "394:\tlearn: 0.8463430\ttotal: 1m 39s\tremaining: 2m 33s\n",
            "395:\tlearn: 0.8428896\ttotal: 1m 40s\tremaining: 2m 32s\n",
            "396:\tlearn: 0.8398947\ttotal: 1m 40s\tremaining: 2m 32s\n",
            "397:\tlearn: 0.8369614\ttotal: 1m 40s\tremaining: 2m 32s\n",
            "398:\tlearn: 0.8341134\ttotal: 1m 40s\tremaining: 2m 31s\n",
            "399:\tlearn: 0.8310318\ttotal: 1m 41s\tremaining: 2m 31s\n",
            "400:\tlearn: 0.8282601\ttotal: 1m 41s\tremaining: 2m 31s\n",
            "401:\tlearn: 0.8250471\ttotal: 1m 41s\tremaining: 2m 31s\n",
            "402:\tlearn: 0.8237162\ttotal: 1m 41s\tremaining: 2m 30s\n",
            "403:\tlearn: 0.8208409\ttotal: 1m 42s\tremaining: 2m 30s\n",
            "404:\tlearn: 0.8180699\ttotal: 1m 42s\tremaining: 2m 30s\n",
            "405:\tlearn: 0.8155698\ttotal: 1m 42s\tremaining: 2m 29s\n",
            "406:\tlearn: 0.8137700\ttotal: 1m 42s\tremaining: 2m 29s\n",
            "407:\tlearn: 0.8117403\ttotal: 1m 42s\tremaining: 2m 29s\n",
            "408:\tlearn: 0.8098851\ttotal: 1m 43s\tremaining: 2m 28s\n",
            "409:\tlearn: 0.8076058\ttotal: 1m 43s\tremaining: 2m 28s\n",
            "410:\tlearn: 0.8052026\ttotal: 1m 43s\tremaining: 2m 28s\n",
            "411:\tlearn: 0.8022966\ttotal: 1m 43s\tremaining: 2m 28s\n",
            "412:\tlearn: 0.8009834\ttotal: 1m 43s\tremaining: 2m 27s\n",
            "413:\tlearn: 0.7988997\ttotal: 1m 44s\tremaining: 2m 27s\n",
            "414:\tlearn: 0.7965328\ttotal: 1m 44s\tremaining: 2m 27s\n",
            "415:\tlearn: 0.7946751\ttotal: 1m 44s\tremaining: 2m 26s\n",
            "416:\tlearn: 0.7924357\ttotal: 1m 44s\tremaining: 2m 26s\n",
            "417:\tlearn: 0.7897831\ttotal: 1m 45s\tremaining: 2m 26s\n",
            "418:\tlearn: 0.7876226\ttotal: 1m 45s\tremaining: 2m 25s\n",
            "419:\tlearn: 0.7850093\ttotal: 1m 45s\tremaining: 2m 25s\n",
            "420:\tlearn: 0.7825126\ttotal: 1m 45s\tremaining: 2m 25s\n",
            "421:\tlearn: 0.7807132\ttotal: 1m 45s\tremaining: 2m 25s\n",
            "422:\tlearn: 0.7781653\ttotal: 1m 46s\tremaining: 2m 24s\n",
            "423:\tlearn: 0.7766167\ttotal: 1m 46s\tremaining: 2m 24s\n",
            "424:\tlearn: 0.7743480\ttotal: 1m 46s\tremaining: 2m 24s\n",
            "425:\tlearn: 0.7721798\ttotal: 1m 46s\tremaining: 2m 23s\n",
            "426:\tlearn: 0.7700388\ttotal: 1m 46s\tremaining: 2m 23s\n",
            "427:\tlearn: 0.7676972\ttotal: 1m 47s\tremaining: 2m 23s\n",
            "428:\tlearn: 0.7659899\ttotal: 1m 47s\tremaining: 2m 22s\n",
            "429:\tlearn: 0.7639048\ttotal: 1m 47s\tremaining: 2m 22s\n",
            "430:\tlearn: 0.7616079\ttotal: 1m 47s\tremaining: 2m 22s\n",
            "431:\tlearn: 0.7587549\ttotal: 1m 48s\tremaining: 2m 22s\n",
            "432:\tlearn: 0.7562545\ttotal: 1m 48s\tremaining: 2m 21s\n",
            "433:\tlearn: 0.7540534\ttotal: 1m 48s\tremaining: 2m 21s\n",
            "434:\tlearn: 0.7521997\ttotal: 1m 48s\tremaining: 2m 21s\n",
            "435:\tlearn: 0.7513197\ttotal: 1m 48s\tremaining: 2m 20s\n",
            "436:\tlearn: 0.7491068\ttotal: 1m 49s\tremaining: 2m 20s\n",
            "437:\tlearn: 0.7479092\ttotal: 1m 49s\tremaining: 2m 20s\n",
            "438:\tlearn: 0.7457645\ttotal: 1m 49s\tremaining: 2m 19s\n",
            "439:\tlearn: 0.7434838\ttotal: 1m 49s\tremaining: 2m 19s\n",
            "440:\tlearn: 0.7418748\ttotal: 1m 50s\tremaining: 2m 19s\n",
            "441:\tlearn: 0.7393799\ttotal: 1m 50s\tremaining: 2m 19s\n",
            "442:\tlearn: 0.7371155\ttotal: 1m 50s\tremaining: 2m 19s\n",
            "443:\tlearn: 0.7345809\ttotal: 1m 51s\tremaining: 2m 19s\n",
            "444:\tlearn: 0.7325108\ttotal: 1m 51s\tremaining: 2m 19s\n",
            "445:\tlearn: 0.7298773\ttotal: 1m 51s\tremaining: 2m 18s\n",
            "446:\tlearn: 0.7276125\ttotal: 1m 52s\tremaining: 2m 18s\n",
            "447:\tlearn: 0.7253381\ttotal: 1m 52s\tremaining: 2m 18s\n",
            "448:\tlearn: 0.7233560\ttotal: 1m 52s\tremaining: 2m 18s\n",
            "449:\tlearn: 0.7217969\ttotal: 1m 53s\tremaining: 2m 18s\n",
            "450:\tlearn: 0.7200868\ttotal: 1m 53s\tremaining: 2m 18s\n",
            "451:\tlearn: 0.7185966\ttotal: 1m 53s\tremaining: 2m 17s\n",
            "452:\tlearn: 0.7163782\ttotal: 1m 53s\tremaining: 2m 17s\n",
            "453:\tlearn: 0.7142812\ttotal: 1m 54s\tremaining: 2m 17s\n",
            "454:\tlearn: 0.7121204\ttotal: 1m 54s\tremaining: 2m 17s\n",
            "455:\tlearn: 0.7105756\ttotal: 1m 54s\tremaining: 2m 16s\n",
            "456:\tlearn: 0.7091731\ttotal: 1m 54s\tremaining: 2m 16s\n",
            "457:\tlearn: 0.7074155\ttotal: 1m 55s\tremaining: 2m 16s\n",
            "458:\tlearn: 0.7058272\ttotal: 1m 55s\tremaining: 2m 15s\n",
            "459:\tlearn: 0.7040597\ttotal: 1m 55s\tremaining: 2m 15s\n",
            "460:\tlearn: 0.7021903\ttotal: 1m 55s\tremaining: 2m 15s\n",
            "461:\tlearn: 0.7000046\ttotal: 1m 55s\tremaining: 2m 14s\n",
            "462:\tlearn: 0.6981272\ttotal: 1m 56s\tremaining: 2m 14s\n",
            "463:\tlearn: 0.6960461\ttotal: 1m 56s\tremaining: 2m 14s\n",
            "464:\tlearn: 0.6940844\ttotal: 1m 56s\tremaining: 2m 14s\n",
            "465:\tlearn: 0.6922653\ttotal: 1m 56s\tremaining: 2m 13s\n",
            "466:\tlearn: 0.6906029\ttotal: 1m 56s\tremaining: 2m 13s\n",
            "467:\tlearn: 0.6894095\ttotal: 1m 57s\tremaining: 2m 13s\n",
            "468:\tlearn: 0.6873224\ttotal: 1m 57s\tremaining: 2m 12s\n",
            "469:\tlearn: 0.6853519\ttotal: 1m 57s\tremaining: 2m 12s\n",
            "470:\tlearn: 0.6841180\ttotal: 1m 57s\tremaining: 2m 12s\n",
            "471:\tlearn: 0.6827610\ttotal: 1m 58s\tremaining: 2m 12s\n",
            "472:\tlearn: 0.6812725\ttotal: 1m 58s\tremaining: 2m 11s\n",
            "473:\tlearn: 0.6795877\ttotal: 1m 58s\tremaining: 2m 11s\n",
            "474:\tlearn: 0.6782243\ttotal: 1m 58s\tremaining: 2m 11s\n",
            "475:\tlearn: 0.6765444\ttotal: 1m 58s\tremaining: 2m 10s\n",
            "476:\tlearn: 0.6749661\ttotal: 1m 59s\tremaining: 2m 10s\n",
            "477:\tlearn: 0.6728539\ttotal: 1m 59s\tremaining: 2m 10s\n",
            "478:\tlearn: 0.6710026\ttotal: 1m 59s\tremaining: 2m 10s\n",
            "479:\tlearn: 0.6691291\ttotal: 1m 59s\tremaining: 2m 9s\n",
            "480:\tlearn: 0.6677191\ttotal: 1m 59s\tremaining: 2m 9s\n",
            "481:\tlearn: 0.6660678\ttotal: 2m\tremaining: 2m 9s\n",
            "482:\tlearn: 0.6646469\ttotal: 2m\tremaining: 2m 8s\n",
            "483:\tlearn: 0.6627433\ttotal: 2m\tremaining: 2m 8s\n",
            "484:\tlearn: 0.6613969\ttotal: 2m\tremaining: 2m 8s\n",
            "485:\tlearn: 0.6599545\ttotal: 2m 1s\tremaining: 2m 8s\n",
            "486:\tlearn: 0.6579890\ttotal: 2m 1s\tremaining: 2m 7s\n",
            "487:\tlearn: 0.6566739\ttotal: 2m 1s\tremaining: 2m 7s\n",
            "488:\tlearn: 0.6551613\ttotal: 2m 1s\tremaining: 2m 7s\n",
            "489:\tlearn: 0.6538954\ttotal: 2m 1s\tremaining: 2m 6s\n",
            "490:\tlearn: 0.6522281\ttotal: 2m 2s\tremaining: 2m 6s\n",
            "491:\tlearn: 0.6504361\ttotal: 2m 2s\tremaining: 2m 6s\n",
            "492:\tlearn: 0.6488265\ttotal: 2m 2s\tremaining: 2m 6s\n",
            "493:\tlearn: 0.6471671\ttotal: 2m 2s\tremaining: 2m 5s\n",
            "494:\tlearn: 0.6453775\ttotal: 2m 3s\tremaining: 2m 5s\n",
            "495:\tlearn: 0.6438245\ttotal: 2m 3s\tremaining: 2m 5s\n",
            "496:\tlearn: 0.6422326\ttotal: 2m 3s\tremaining: 2m 4s\n",
            "497:\tlearn: 0.6411897\ttotal: 2m 3s\tremaining: 2m 4s\n",
            "498:\tlearn: 0.6394586\ttotal: 2m 4s\tremaining: 2m 4s\n",
            "499:\tlearn: 0.6383458\ttotal: 2m 4s\tremaining: 2m 4s\n",
            "500:\tlearn: 0.6366896\ttotal: 2m 4s\tremaining: 2m 4s\n",
            "501:\tlearn: 0.6351064\ttotal: 2m 5s\tremaining: 2m 4s\n",
            "502:\tlearn: 0.6333063\ttotal: 2m 5s\tremaining: 2m 3s\n",
            "503:\tlearn: 0.6316350\ttotal: 2m 5s\tremaining: 2m 3s\n",
            "504:\tlearn: 0.6302432\ttotal: 2m 6s\tremaining: 2m 3s\n",
            "505:\tlearn: 0.6288295\ttotal: 2m 6s\tremaining: 2m 3s\n",
            "506:\tlearn: 0.6273112\ttotal: 2m 6s\tremaining: 2m 3s\n",
            "507:\tlearn: 0.6262689\ttotal: 2m 7s\tremaining: 2m 3s\n",
            "508:\tlearn: 0.6246650\ttotal: 2m 7s\tremaining: 2m 2s\n",
            "509:\tlearn: 0.6230145\ttotal: 2m 7s\tremaining: 2m 2s\n",
            "510:\tlearn: 0.6209440\ttotal: 2m 7s\tremaining: 2m 2s\n",
            "511:\tlearn: 0.6193728\ttotal: 2m 8s\tremaining: 2m 2s\n",
            "512:\tlearn: 0.6180248\ttotal: 2m 8s\tremaining: 2m 1s\n",
            "513:\tlearn: 0.6166893\ttotal: 2m 8s\tremaining: 2m 1s\n",
            "514:\tlearn: 0.6150902\ttotal: 2m 8s\tremaining: 2m 1s\n",
            "515:\tlearn: 0.6135621\ttotal: 2m 9s\tremaining: 2m 1s\n",
            "516:\tlearn: 0.6123397\ttotal: 2m 9s\tremaining: 2m\n",
            "517:\tlearn: 0.6109896\ttotal: 2m 9s\tremaining: 2m\n",
            "518:\tlearn: 0.6092210\ttotal: 2m 9s\tremaining: 2m\n",
            "519:\tlearn: 0.6080409\ttotal: 2m 9s\tremaining: 1m 59s\n",
            "520:\tlearn: 0.6064034\ttotal: 2m 10s\tremaining: 1m 59s\n",
            "521:\tlearn: 0.6051036\ttotal: 2m 10s\tremaining: 1m 59s\n",
            "522:\tlearn: 0.6034480\ttotal: 2m 10s\tremaining: 1m 59s\n",
            "523:\tlearn: 0.6022027\ttotal: 2m 10s\tremaining: 1m 58s\n",
            "524:\tlearn: 0.6006735\ttotal: 2m 11s\tremaining: 1m 58s\n",
            "525:\tlearn: 0.5995908\ttotal: 2m 11s\tremaining: 1m 58s\n",
            "526:\tlearn: 0.5987380\ttotal: 2m 11s\tremaining: 1m 58s\n",
            "527:\tlearn: 0.5974476\ttotal: 2m 11s\tremaining: 1m 57s\n",
            "528:\tlearn: 0.5956654\ttotal: 2m 11s\tremaining: 1m 57s\n",
            "529:\tlearn: 0.5944658\ttotal: 2m 12s\tremaining: 1m 57s\n",
            "530:\tlearn: 0.5932151\ttotal: 2m 12s\tremaining: 1m 56s\n",
            "531:\tlearn: 0.5920091\ttotal: 2m 12s\tremaining: 1m 56s\n",
            "532:\tlearn: 0.5910692\ttotal: 2m 12s\tremaining: 1m 56s\n",
            "533:\tlearn: 0.5895445\ttotal: 2m 13s\tremaining: 1m 56s\n",
            "534:\tlearn: 0.5882209\ttotal: 2m 13s\tremaining: 1m 55s\n",
            "535:\tlearn: 0.5870511\ttotal: 2m 13s\tremaining: 1m 55s\n",
            "536:\tlearn: 0.5856127\ttotal: 2m 13s\tremaining: 1m 55s\n",
            "537:\tlearn: 0.5845241\ttotal: 2m 13s\tremaining: 1m 54s\n",
            "538:\tlearn: 0.5837564\ttotal: 2m 14s\tremaining: 1m 54s\n",
            "539:\tlearn: 0.5826250\ttotal: 2m 14s\tremaining: 1m 54s\n",
            "540:\tlearn: 0.5816165\ttotal: 2m 14s\tremaining: 1m 54s\n",
            "541:\tlearn: 0.5806242\ttotal: 2m 14s\tremaining: 1m 53s\n",
            "542:\tlearn: 0.5799328\ttotal: 2m 14s\tremaining: 1m 53s\n",
            "543:\tlearn: 0.5783076\ttotal: 2m 15s\tremaining: 1m 53s\n",
            "544:\tlearn: 0.5769668\ttotal: 2m 15s\tremaining: 1m 53s\n",
            "545:\tlearn: 0.5756945\ttotal: 2m 15s\tremaining: 1m 52s\n",
            "546:\tlearn: 0.5746024\ttotal: 2m 15s\tremaining: 1m 52s\n",
            "547:\tlearn: 0.5736611\ttotal: 2m 16s\tremaining: 1m 52s\n",
            "548:\tlearn: 0.5723603\ttotal: 2m 16s\tremaining: 1m 51s\n",
            "549:\tlearn: 0.5711805\ttotal: 2m 16s\tremaining: 1m 51s\n",
            "550:\tlearn: 0.5697866\ttotal: 2m 16s\tremaining: 1m 51s\n",
            "551:\tlearn: 0.5685687\ttotal: 2m 16s\tremaining: 1m 51s\n",
            "552:\tlearn: 0.5671260\ttotal: 2m 17s\tremaining: 1m 50s\n",
            "553:\tlearn: 0.5659120\ttotal: 2m 17s\tremaining: 1m 50s\n",
            "554:\tlearn: 0.5648746\ttotal: 2m 17s\tremaining: 1m 50s\n",
            "555:\tlearn: 0.5634765\ttotal: 2m 17s\tremaining: 1m 50s\n",
            "556:\tlearn: 0.5618762\ttotal: 2m 18s\tremaining: 1m 50s\n",
            "557:\tlearn: 0.5610286\ttotal: 2m 18s\tremaining: 1m 49s\n",
            "558:\tlearn: 0.5599146\ttotal: 2m 18s\tremaining: 1m 49s\n",
            "559:\tlearn: 0.5587921\ttotal: 2m 19s\tremaining: 1m 49s\n",
            "560:\tlearn: 0.5579202\ttotal: 2m 19s\tremaining: 1m 49s\n",
            "561:\tlearn: 0.5571049\ttotal: 2m 19s\tremaining: 1m 49s\n",
            "562:\tlearn: 0.5559193\ttotal: 2m 20s\tremaining: 1m 48s\n",
            "563:\tlearn: 0.5550574\ttotal: 2m 20s\tremaining: 1m 48s\n",
            "564:\tlearn: 0.5538667\ttotal: 2m 21s\tremaining: 1m 48s\n",
            "565:\tlearn: 0.5525578\ttotal: 2m 21s\tremaining: 1m 48s\n",
            "566:\tlearn: 0.5512299\ttotal: 2m 21s\tremaining: 1m 48s\n",
            "567:\tlearn: 0.5498300\ttotal: 2m 21s\tremaining: 1m 47s\n",
            "568:\tlearn: 0.5488729\ttotal: 2m 21s\tremaining: 1m 47s\n",
            "569:\tlearn: 0.5479466\ttotal: 2m 22s\tremaining: 1m 47s\n",
            "570:\tlearn: 0.5469241\ttotal: 2m 22s\tremaining: 1m 46s\n",
            "571:\tlearn: 0.5459525\ttotal: 2m 22s\tremaining: 1m 46s\n",
            "572:\tlearn: 0.5444583\ttotal: 2m 22s\tremaining: 1m 46s\n",
            "573:\tlearn: 0.5431640\ttotal: 2m 23s\tremaining: 1m 46s\n",
            "574:\tlearn: 0.5424257\ttotal: 2m 23s\tremaining: 1m 45s\n",
            "575:\tlearn: 0.5412315\ttotal: 2m 23s\tremaining: 1m 45s\n",
            "576:\tlearn: 0.5401873\ttotal: 2m 23s\tremaining: 1m 45s\n",
            "577:\tlearn: 0.5390496\ttotal: 2m 23s\tremaining: 1m 45s\n",
            "578:\tlearn: 0.5377484\ttotal: 2m 24s\tremaining: 1m 44s\n",
            "579:\tlearn: 0.5363533\ttotal: 2m 24s\tremaining: 1m 44s\n",
            "580:\tlearn: 0.5353442\ttotal: 2m 24s\tremaining: 1m 44s\n",
            "581:\tlearn: 0.5338925\ttotal: 2m 24s\tremaining: 1m 43s\n",
            "582:\tlearn: 0.5327144\ttotal: 2m 24s\tremaining: 1m 43s\n",
            "583:\tlearn: 0.5316004\ttotal: 2m 25s\tremaining: 1m 43s\n",
            "584:\tlearn: 0.5305236\ttotal: 2m 25s\tremaining: 1m 43s\n",
            "585:\tlearn: 0.5295184\ttotal: 2m 25s\tremaining: 1m 42s\n",
            "586:\tlearn: 0.5285945\ttotal: 2m 25s\tremaining: 1m 42s\n",
            "587:\tlearn: 0.5271592\ttotal: 2m 26s\tremaining: 1m 42s\n",
            "588:\tlearn: 0.5259570\ttotal: 2m 26s\tremaining: 1m 42s\n",
            "589:\tlearn: 0.5250947\ttotal: 2m 26s\tremaining: 1m 41s\n",
            "590:\tlearn: 0.5241100\ttotal: 2m 26s\tremaining: 1m 41s\n",
            "591:\tlearn: 0.5228069\ttotal: 2m 26s\tremaining: 1m 41s\n",
            "592:\tlearn: 0.5218093\ttotal: 2m 27s\tremaining: 1m 40s\n",
            "593:\tlearn: 0.5206692\ttotal: 2m 27s\tremaining: 1m 40s\n",
            "594:\tlearn: 0.5201347\ttotal: 2m 27s\tremaining: 1m 40s\n",
            "595:\tlearn: 0.5189961\ttotal: 2m 27s\tremaining: 1m 40s\n",
            "596:\tlearn: 0.5179494\ttotal: 2m 27s\tremaining: 1m 39s\n",
            "597:\tlearn: 0.5172351\ttotal: 2m 28s\tremaining: 1m 39s\n",
            "598:\tlearn: 0.5159698\ttotal: 2m 28s\tremaining: 1m 39s\n",
            "599:\tlearn: 0.5150446\ttotal: 2m 28s\tremaining: 1m 39s\n",
            "600:\tlearn: 0.5138044\ttotal: 2m 28s\tremaining: 1m 38s\n",
            "601:\tlearn: 0.5126099\ttotal: 2m 28s\tremaining: 1m 38s\n",
            "602:\tlearn: 0.5114785\ttotal: 2m 29s\tremaining: 1m 38s\n",
            "603:\tlearn: 0.5102950\ttotal: 2m 29s\tremaining: 1m 37s\n",
            "604:\tlearn: 0.5090819\ttotal: 2m 29s\tremaining: 1m 37s\n",
            "605:\tlearn: 0.5083789\ttotal: 2m 29s\tremaining: 1m 37s\n",
            "606:\tlearn: 0.5074522\ttotal: 2m 30s\tremaining: 1m 37s\n",
            "607:\tlearn: 0.5061604\ttotal: 2m 30s\tremaining: 1m 36s\n",
            "608:\tlearn: 0.5051231\ttotal: 2m 30s\tremaining: 1m 36s\n",
            "609:\tlearn: 0.5038549\ttotal: 2m 30s\tremaining: 1m 36s\n",
            "610:\tlearn: 0.5027998\ttotal: 2m 30s\tremaining: 1m 36s\n",
            "611:\tlearn: 0.5019328\ttotal: 2m 31s\tremaining: 1m 35s\n",
            "612:\tlearn: 0.5007730\ttotal: 2m 31s\tremaining: 1m 35s\n",
            "613:\tlearn: 0.4994455\ttotal: 2m 31s\tremaining: 1m 35s\n",
            "614:\tlearn: 0.4985509\ttotal: 2m 32s\tremaining: 1m 35s\n",
            "615:\tlearn: 0.4975219\ttotal: 2m 32s\tremaining: 1m 35s\n",
            "616:\tlearn: 0.4966510\ttotal: 2m 32s\tremaining: 1m 34s\n",
            "617:\tlearn: 0.4957418\ttotal: 2m 33s\tremaining: 1m 34s\n",
            "618:\tlearn: 0.4945017\ttotal: 2m 33s\tremaining: 1m 34s\n",
            "619:\tlearn: 0.4936662\ttotal: 2m 33s\tremaining: 1m 34s\n",
            "620:\tlearn: 0.4927085\ttotal: 2m 34s\tremaining: 1m 34s\n",
            "621:\tlearn: 0.4915059\ttotal: 2m 34s\tremaining: 1m 33s\n",
            "622:\tlearn: 0.4908853\ttotal: 2m 34s\tremaining: 1m 33s\n",
            "623:\tlearn: 0.4899413\ttotal: 2m 35s\tremaining: 1m 33s\n",
            "624:\tlearn: 0.4889944\ttotal: 2m 35s\tremaining: 1m 33s\n",
            "625:\tlearn: 0.4881765\ttotal: 2m 35s\tremaining: 1m 32s\n",
            "626:\tlearn: 0.4875520\ttotal: 2m 35s\tremaining: 1m 32s\n",
            "627:\tlearn: 0.4868933\ttotal: 2m 35s\tremaining: 1m 32s\n",
            "628:\tlearn: 0.4860102\ttotal: 2m 36s\tremaining: 1m 32s\n",
            "629:\tlearn: 0.4851665\ttotal: 2m 36s\tremaining: 1m 31s\n",
            "630:\tlearn: 0.4844463\ttotal: 2m 36s\tremaining: 1m 31s\n",
            "631:\tlearn: 0.4835285\ttotal: 2m 36s\tremaining: 1m 31s\n",
            "632:\tlearn: 0.4825858\ttotal: 2m 36s\tremaining: 1m 31s\n",
            "633:\tlearn: 0.4817749\ttotal: 2m 37s\tremaining: 1m 30s\n",
            "634:\tlearn: 0.4807677\ttotal: 2m 37s\tremaining: 1m 30s\n",
            "635:\tlearn: 0.4797792\ttotal: 2m 37s\tremaining: 1m 30s\n",
            "636:\tlearn: 0.4785151\ttotal: 2m 37s\tremaining: 1m 29s\n",
            "637:\tlearn: 0.4778748\ttotal: 2m 38s\tremaining: 1m 29s\n",
            "638:\tlearn: 0.4768183\ttotal: 2m 38s\tremaining: 1m 29s\n",
            "639:\tlearn: 0.4758427\ttotal: 2m 38s\tremaining: 1m 29s\n",
            "640:\tlearn: 0.4747884\ttotal: 2m 38s\tremaining: 1m 28s\n",
            "641:\tlearn: 0.4741268\ttotal: 2m 38s\tremaining: 1m 28s\n",
            "642:\tlearn: 0.4730406\ttotal: 2m 39s\tremaining: 1m 28s\n",
            "643:\tlearn: 0.4719780\ttotal: 2m 39s\tremaining: 1m 28s\n",
            "644:\tlearn: 0.4708695\ttotal: 2m 39s\tremaining: 1m 27s\n",
            "645:\tlearn: 0.4699828\ttotal: 2m 39s\tremaining: 1m 27s\n",
            "646:\tlearn: 0.4693578\ttotal: 2m 40s\tremaining: 1m 27s\n",
            "647:\tlearn: 0.4683282\ttotal: 2m 40s\tremaining: 1m 27s\n",
            "648:\tlearn: 0.4675931\ttotal: 2m 40s\tremaining: 1m 26s\n",
            "649:\tlearn: 0.4669037\ttotal: 2m 40s\tremaining: 1m 26s\n",
            "650:\tlearn: 0.4663413\ttotal: 2m 40s\tremaining: 1m 26s\n",
            "651:\tlearn: 0.4653513\ttotal: 2m 41s\tremaining: 1m 25s\n",
            "652:\tlearn: 0.4643214\ttotal: 2m 41s\tremaining: 1m 25s\n",
            "653:\tlearn: 0.4635907\ttotal: 2m 41s\tremaining: 1m 25s\n",
            "654:\tlearn: 0.4626492\ttotal: 2m 41s\tremaining: 1m 25s\n",
            "655:\tlearn: 0.4618077\ttotal: 2m 41s\tremaining: 1m 24s\n",
            "656:\tlearn: 0.4608343\ttotal: 2m 42s\tremaining: 1m 24s\n",
            "657:\tlearn: 0.4598656\ttotal: 2m 42s\tremaining: 1m 24s\n",
            "658:\tlearn: 0.4588116\ttotal: 2m 42s\tremaining: 1m 24s\n",
            "659:\tlearn: 0.4579279\ttotal: 2m 42s\tremaining: 1m 23s\n",
            "660:\tlearn: 0.4571217\ttotal: 2m 43s\tremaining: 1m 23s\n",
            "661:\tlearn: 0.4562762\ttotal: 2m 43s\tremaining: 1m 23s\n",
            "662:\tlearn: 0.4556883\ttotal: 2m 43s\tremaining: 1m 23s\n",
            "663:\tlearn: 0.4548972\ttotal: 2m 43s\tremaining: 1m 22s\n",
            "664:\tlearn: 0.4541168\ttotal: 2m 43s\tremaining: 1m 22s\n",
            "665:\tlearn: 0.4533929\ttotal: 2m 44s\tremaining: 1m 22s\n",
            "666:\tlearn: 0.4525590\ttotal: 2m 44s\tremaining: 1m 22s\n",
            "667:\tlearn: 0.4516735\ttotal: 2m 44s\tremaining: 1m 21s\n",
            "668:\tlearn: 0.4512612\ttotal: 2m 44s\tremaining: 1m 21s\n",
            "669:\tlearn: 0.4504689\ttotal: 2m 44s\tremaining: 1m 21s\n",
            "670:\tlearn: 0.4499460\ttotal: 2m 45s\tremaining: 1m 21s\n",
            "671:\tlearn: 0.4491990\ttotal: 2m 45s\tremaining: 1m 20s\n",
            "672:\tlearn: 0.4480947\ttotal: 2m 45s\tremaining: 1m 20s\n",
            "673:\tlearn: 0.4472594\ttotal: 2m 46s\tremaining: 1m 20s\n",
            "674:\tlearn: 0.4464199\ttotal: 2m 46s\tremaining: 1m 20s\n",
            "675:\tlearn: 0.4458410\ttotal: 2m 47s\tremaining: 1m 20s\n",
            "676:\tlearn: 0.4450856\ttotal: 2m 47s\tremaining: 1m 19s\n",
            "677:\tlearn: 0.4442706\ttotal: 2m 47s\tremaining: 1m 19s\n",
            "678:\tlearn: 0.4434691\ttotal: 2m 48s\tremaining: 1m 19s\n",
            "679:\tlearn: 0.4424431\ttotal: 2m 48s\tremaining: 1m 19s\n",
            "680:\tlearn: 0.4419070\ttotal: 2m 48s\tremaining: 1m 19s\n",
            "681:\tlearn: 0.4412188\ttotal: 2m 48s\tremaining: 1m 18s\n",
            "682:\tlearn: 0.4405875\ttotal: 2m 49s\tremaining: 1m 18s\n",
            "683:\tlearn: 0.4399056\ttotal: 2m 49s\tremaining: 1m 18s\n",
            "684:\tlearn: 0.4390576\ttotal: 2m 49s\tremaining: 1m 17s\n",
            "685:\tlearn: 0.4382541\ttotal: 2m 49s\tremaining: 1m 17s\n",
            "686:\tlearn: 0.4375349\ttotal: 2m 49s\tremaining: 1m 17s\n",
            "687:\tlearn: 0.4367388\ttotal: 2m 50s\tremaining: 1m 17s\n",
            "688:\tlearn: 0.4361016\ttotal: 2m 50s\tremaining: 1m 16s\n",
            "689:\tlearn: 0.4353393\ttotal: 2m 50s\tremaining: 1m 16s\n",
            "690:\tlearn: 0.4344988\ttotal: 2m 50s\tremaining: 1m 16s\n",
            "691:\tlearn: 0.4338498\ttotal: 2m 51s\tremaining: 1m 16s\n",
            "692:\tlearn: 0.4329591\ttotal: 2m 51s\tremaining: 1m 15s\n",
            "693:\tlearn: 0.4321695\ttotal: 2m 51s\tremaining: 1m 15s\n",
            "694:\tlearn: 0.4314930\ttotal: 2m 51s\tremaining: 1m 15s\n",
            "695:\tlearn: 0.4305782\ttotal: 2m 51s\tremaining: 1m 15s\n",
            "696:\tlearn: 0.4298464\ttotal: 2m 52s\tremaining: 1m 14s\n",
            "697:\tlearn: 0.4293522\ttotal: 2m 52s\tremaining: 1m 14s\n",
            "698:\tlearn: 0.4285383\ttotal: 2m 52s\tremaining: 1m 14s\n",
            "699:\tlearn: 0.4275901\ttotal: 2m 52s\tremaining: 1m 14s\n",
            "700:\tlearn: 0.4269121\ttotal: 2m 52s\tremaining: 1m 13s\n",
            "701:\tlearn: 0.4262811\ttotal: 2m 53s\tremaining: 1m 13s\n",
            "702:\tlearn: 0.4254573\ttotal: 2m 53s\tremaining: 1m 13s\n",
            "703:\tlearn: 0.4248132\ttotal: 2m 53s\tremaining: 1m 13s\n",
            "704:\tlearn: 0.4238527\ttotal: 2m 53s\tremaining: 1m 12s\n",
            "705:\tlearn: 0.4229599\ttotal: 2m 54s\tremaining: 1m 12s\n",
            "706:\tlearn: 0.4222115\ttotal: 2m 54s\tremaining: 1m 12s\n",
            "707:\tlearn: 0.4213258\ttotal: 2m 54s\tremaining: 1m 11s\n",
            "708:\tlearn: 0.4205913\ttotal: 2m 54s\tremaining: 1m 11s\n",
            "709:\tlearn: 0.4197935\ttotal: 2m 54s\tremaining: 1m 11s\n",
            "710:\tlearn: 0.4193189\ttotal: 2m 55s\tremaining: 1m 11s\n",
            "711:\tlearn: 0.4185300\ttotal: 2m 55s\tremaining: 1m 10s\n",
            "712:\tlearn: 0.4178979\ttotal: 2m 55s\tremaining: 1m 10s\n",
            "713:\tlearn: 0.4170492\ttotal: 2m 55s\tremaining: 1m 10s\n",
            "714:\tlearn: 0.4162075\ttotal: 2m 55s\tremaining: 1m 10s\n",
            "715:\tlearn: 0.4155135\ttotal: 2m 56s\tremaining: 1m 9s\n",
            "716:\tlearn: 0.4147526\ttotal: 2m 56s\tremaining: 1m 9s\n",
            "717:\tlearn: 0.4143112\ttotal: 2m 56s\tremaining: 1m 9s\n",
            "718:\tlearn: 0.4135542\ttotal: 2m 56s\tremaining: 1m 9s\n",
            "719:\tlearn: 0.4126891\ttotal: 2m 57s\tremaining: 1m 8s\n",
            "720:\tlearn: 0.4121290\ttotal: 2m 57s\tremaining: 1m 8s\n",
            "721:\tlearn: 0.4113182\ttotal: 2m 57s\tremaining: 1m 8s\n",
            "722:\tlearn: 0.4109050\ttotal: 2m 57s\tremaining: 1m 8s\n",
            "723:\tlearn: 0.4101312\ttotal: 2m 57s\tremaining: 1m 7s\n",
            "724:\tlearn: 0.4093672\ttotal: 2m 58s\tremaining: 1m 7s\n",
            "725:\tlearn: 0.4087947\ttotal: 2m 58s\tremaining: 1m 7s\n",
            "726:\tlearn: 0.4079489\ttotal: 2m 58s\tremaining: 1m 7s\n",
            "727:\tlearn: 0.4072140\ttotal: 2m 58s\tremaining: 1m 6s\n",
            "728:\tlearn: 0.4066101\ttotal: 2m 59s\tremaining: 1m 6s\n",
            "729:\tlearn: 0.4061531\ttotal: 2m 59s\tremaining: 1m 6s\n",
            "730:\tlearn: 0.4055038\ttotal: 2m 59s\tremaining: 1m 6s\n",
            "731:\tlearn: 0.4048656\ttotal: 3m\tremaining: 1m 5s\n",
            "732:\tlearn: 0.4042368\ttotal: 3m\tremaining: 1m 5s\n",
            "733:\tlearn: 0.4037613\ttotal: 3m\tremaining: 1m 5s\n",
            "734:\tlearn: 0.4028226\ttotal: 3m 1s\tremaining: 1m 5s\n",
            "735:\tlearn: 0.4020331\ttotal: 3m 1s\tremaining: 1m 5s\n",
            "736:\tlearn: 0.4014667\ttotal: 3m 2s\tremaining: 1m 4s\n",
            "737:\tlearn: 0.4009687\ttotal: 3m 2s\tremaining: 1m 4s\n",
            "738:\tlearn: 0.4002660\ttotal: 3m 2s\tremaining: 1m 4s\n",
            "739:\tlearn: 0.3997253\ttotal: 3m 2s\tremaining: 1m 4s\n",
            "740:\tlearn: 0.3989771\ttotal: 3m 2s\tremaining: 1m 3s\n",
            "741:\tlearn: 0.3983381\ttotal: 3m 3s\tremaining: 1m 3s\n",
            "742:\tlearn: 0.3978746\ttotal: 3m 3s\tremaining: 1m 3s\n",
            "743:\tlearn: 0.3971902\ttotal: 3m 3s\tremaining: 1m 3s\n",
            "744:\tlearn: 0.3966973\ttotal: 3m 3s\tremaining: 1m 2s\n",
            "745:\tlearn: 0.3961521\ttotal: 3m 4s\tremaining: 1m 2s\n",
            "746:\tlearn: 0.3955731\ttotal: 3m 4s\tremaining: 1m 2s\n",
            "747:\tlearn: 0.3947308\ttotal: 3m 4s\tremaining: 1m 2s\n",
            "748:\tlearn: 0.3942059\ttotal: 3m 4s\tremaining: 1m 1s\n",
            "749:\tlearn: 0.3935338\ttotal: 3m 4s\tremaining: 1m 1s\n",
            "750:\tlearn: 0.3930576\ttotal: 3m 5s\tremaining: 1m 1s\n",
            "751:\tlearn: 0.3925431\ttotal: 3m 5s\tremaining: 1m 1s\n",
            "752:\tlearn: 0.3919087\ttotal: 3m 5s\tremaining: 1m\n",
            "753:\tlearn: 0.3913411\ttotal: 3m 5s\tremaining: 1m\n",
            "754:\tlearn: 0.3907164\ttotal: 3m 5s\tremaining: 1m\n",
            "755:\tlearn: 0.3900960\ttotal: 3m 6s\tremaining: 1m\n",
            "756:\tlearn: 0.3893457\ttotal: 3m 6s\tremaining: 59.8s\n",
            "757:\tlearn: 0.3888328\ttotal: 3m 6s\tremaining: 59.6s\n",
            "758:\tlearn: 0.3882633\ttotal: 3m 6s\tremaining: 59.3s\n",
            "759:\tlearn: 0.3877023\ttotal: 3m 7s\tremaining: 59.1s\n",
            "760:\tlearn: 0.3869373\ttotal: 3m 7s\tremaining: 58.8s\n",
            "761:\tlearn: 0.3861687\ttotal: 3m 7s\tremaining: 58.6s\n",
            "762:\tlearn: 0.3854370\ttotal: 3m 7s\tremaining: 58.3s\n",
            "763:\tlearn: 0.3847539\ttotal: 3m 7s\tremaining: 58.1s\n",
            "764:\tlearn: 0.3842305\ttotal: 3m 8s\tremaining: 57.8s\n",
            "765:\tlearn: 0.3835368\ttotal: 3m 8s\tremaining: 57.6s\n",
            "766:\tlearn: 0.3829190\ttotal: 3m 8s\tremaining: 57.3s\n",
            "767:\tlearn: 0.3822337\ttotal: 3m 8s\tremaining: 57s\n",
            "768:\tlearn: 0.3816031\ttotal: 3m 9s\tremaining: 56.8s\n",
            "769:\tlearn: 0.3811500\ttotal: 3m 9s\tremaining: 56.5s\n",
            "770:\tlearn: 0.3805726\ttotal: 3m 9s\tremaining: 56.3s\n",
            "771:\tlearn: 0.3801207\ttotal: 3m 9s\tremaining: 56s\n",
            "772:\tlearn: 0.3796570\ttotal: 3m 9s\tremaining: 55.8s\n",
            "773:\tlearn: 0.3791921\ttotal: 3m 10s\tremaining: 55.5s\n",
            "774:\tlearn: 0.3786330\ttotal: 3m 10s\tremaining: 55.3s\n",
            "775:\tlearn: 0.3781598\ttotal: 3m 10s\tremaining: 55s\n",
            "776:\tlearn: 0.3775793\ttotal: 3m 10s\tremaining: 54.7s\n",
            "777:\tlearn: 0.3770294\ttotal: 3m 10s\tremaining: 54.5s\n",
            "778:\tlearn: 0.3764116\ttotal: 3m 11s\tremaining: 54.2s\n",
            "779:\tlearn: 0.3757474\ttotal: 3m 11s\tremaining: 54s\n",
            "780:\tlearn: 0.3752318\ttotal: 3m 11s\tremaining: 53.7s\n",
            "781:\tlearn: 0.3743815\ttotal: 3m 11s\tremaining: 53.5s\n",
            "782:\tlearn: 0.3738527\ttotal: 3m 12s\tremaining: 53.2s\n",
            "783:\tlearn: 0.3734145\ttotal: 3m 12s\tremaining: 53s\n",
            "784:\tlearn: 0.3728193\ttotal: 3m 12s\tremaining: 52.8s\n",
            "785:\tlearn: 0.3723093\ttotal: 3m 13s\tremaining: 52.6s\n",
            "786:\tlearn: 0.3716957\ttotal: 3m 13s\tremaining: 52.3s\n",
            "787:\tlearn: 0.3711900\ttotal: 3m 13s\tremaining: 52.1s\n",
            "788:\tlearn: 0.3706731\ttotal: 3m 14s\tremaining: 51.9s\n",
            "789:\tlearn: 0.3702627\ttotal: 3m 14s\tremaining: 51.7s\n",
            "790:\tlearn: 0.3694857\ttotal: 3m 14s\tremaining: 51.5s\n",
            "791:\tlearn: 0.3688800\ttotal: 3m 15s\tremaining: 51.3s\n",
            "792:\tlearn: 0.3682672\ttotal: 3m 15s\tremaining: 51s\n",
            "793:\tlearn: 0.3678503\ttotal: 3m 15s\tremaining: 50.8s\n",
            "794:\tlearn: 0.3674295\ttotal: 3m 16s\tremaining: 50.6s\n",
            "795:\tlearn: 0.3669568\ttotal: 3m 16s\tremaining: 50.3s\n",
            "796:\tlearn: 0.3662158\ttotal: 3m 16s\tremaining: 50.1s\n",
            "797:\tlearn: 0.3656569\ttotal: 3m 16s\tremaining: 49.8s\n",
            "798:\tlearn: 0.3649824\ttotal: 3m 17s\tremaining: 49.6s\n",
            "799:\tlearn: 0.3643760\ttotal: 3m 17s\tremaining: 49.3s\n",
            "800:\tlearn: 0.3637423\ttotal: 3m 17s\tremaining: 49.1s\n",
            "801:\tlearn: 0.3631810\ttotal: 3m 17s\tremaining: 48.8s\n",
            "802:\tlearn: 0.3628084\ttotal: 3m 17s\tremaining: 48.6s\n",
            "803:\tlearn: 0.3621493\ttotal: 3m 18s\tremaining: 48.3s\n",
            "804:\tlearn: 0.3616366\ttotal: 3m 18s\tremaining: 48.1s\n",
            "805:\tlearn: 0.3611443\ttotal: 3m 18s\tremaining: 47.8s\n",
            "806:\tlearn: 0.3607767\ttotal: 3m 18s\tremaining: 47.5s\n",
            "807:\tlearn: 0.3602267\ttotal: 3m 19s\tremaining: 47.3s\n",
            "808:\tlearn: 0.3596118\ttotal: 3m 19s\tremaining: 47s\n",
            "809:\tlearn: 0.3589945\ttotal: 3m 19s\tremaining: 46.8s\n",
            "810:\tlearn: 0.3585263\ttotal: 3m 19s\tremaining: 46.5s\n",
            "811:\tlearn: 0.3579262\ttotal: 3m 19s\tremaining: 46.3s\n",
            "812:\tlearn: 0.3576075\ttotal: 3m 20s\tremaining: 46s\n",
            "813:\tlearn: 0.3569620\ttotal: 3m 20s\tremaining: 45.8s\n",
            "814:\tlearn: 0.3564503\ttotal: 3m 20s\tremaining: 45.5s\n",
            "815:\tlearn: 0.3560060\ttotal: 3m 20s\tremaining: 45.3s\n",
            "816:\tlearn: 0.3556137\ttotal: 3m 20s\tremaining: 45s\n",
            "817:\tlearn: 0.3552478\ttotal: 3m 21s\tremaining: 44.8s\n",
            "818:\tlearn: 0.3547075\ttotal: 3m 21s\tremaining: 44.5s\n",
            "819:\tlearn: 0.3542071\ttotal: 3m 21s\tremaining: 44.3s\n",
            "820:\tlearn: 0.3535829\ttotal: 3m 21s\tremaining: 44s\n",
            "821:\tlearn: 0.3531807\ttotal: 3m 22s\tremaining: 43.7s\n",
            "822:\tlearn: 0.3526035\ttotal: 3m 22s\tremaining: 43.5s\n",
            "823:\tlearn: 0.3521406\ttotal: 3m 22s\tremaining: 43.2s\n",
            "824:\tlearn: 0.3516978\ttotal: 3m 22s\tremaining: 43s\n",
            "825:\tlearn: 0.3510628\ttotal: 3m 22s\tremaining: 42.7s\n",
            "826:\tlearn: 0.3504992\ttotal: 3m 23s\tremaining: 42.5s\n",
            "827:\tlearn: 0.3500789\ttotal: 3m 23s\tremaining: 42.2s\n",
            "828:\tlearn: 0.3496240\ttotal: 3m 23s\tremaining: 42s\n",
            "829:\tlearn: 0.3491592\ttotal: 3m 23s\tremaining: 41.7s\n",
            "830:\tlearn: 0.3488120\ttotal: 3m 23s\tremaining: 41.5s\n",
            "831:\tlearn: 0.3483134\ttotal: 3m 24s\tremaining: 41.2s\n",
            "832:\tlearn: 0.3476280\ttotal: 3m 24s\tremaining: 41s\n",
            "833:\tlearn: 0.3470671\ttotal: 3m 24s\tremaining: 40.7s\n",
            "834:\tlearn: 0.3465790\ttotal: 3m 24s\tremaining: 40.5s\n",
            "835:\tlearn: 0.3460839\ttotal: 3m 25s\tremaining: 40.2s\n",
            "836:\tlearn: 0.3457121\ttotal: 3m 25s\tremaining: 40s\n",
            "837:\tlearn: 0.3451092\ttotal: 3m 25s\tremaining: 39.7s\n",
            "838:\tlearn: 0.3447461\ttotal: 3m 25s\tremaining: 39.5s\n",
            "839:\tlearn: 0.3444131\ttotal: 3m 25s\tremaining: 39.2s\n",
            "840:\tlearn: 0.3439768\ttotal: 3m 26s\tremaining: 39s\n",
            "841:\tlearn: 0.3435164\ttotal: 3m 26s\tremaining: 38.7s\n",
            "842:\tlearn: 0.3429395\ttotal: 3m 26s\tremaining: 38.5s\n",
            "843:\tlearn: 0.3424827\ttotal: 3m 27s\tremaining: 38.3s\n",
            "844:\tlearn: 0.3421395\ttotal: 3m 27s\tremaining: 38s\n",
            "845:\tlearn: 0.3416788\ttotal: 3m 27s\tremaining: 37.8s\n",
            "846:\tlearn: 0.3412838\ttotal: 3m 28s\tremaining: 37.6s\n",
            "847:\tlearn: 0.3407717\ttotal: 3m 28s\tremaining: 37.4s\n",
            "848:\tlearn: 0.3402633\ttotal: 3m 28s\tremaining: 37.1s\n",
            "849:\tlearn: 0.3397228\ttotal: 3m 29s\tremaining: 36.9s\n",
            "850:\tlearn: 0.3393676\ttotal: 3m 29s\tremaining: 36.7s\n",
            "851:\tlearn: 0.3390527\ttotal: 3m 29s\tremaining: 36.5s\n",
            "852:\tlearn: 0.3385921\ttotal: 3m 30s\tremaining: 36.2s\n",
            "853:\tlearn: 0.3383178\ttotal: 3m 30s\tremaining: 36s\n",
            "854:\tlearn: 0.3378813\ttotal: 3m 30s\tremaining: 35.7s\n",
            "855:\tlearn: 0.3374270\ttotal: 3m 30s\tremaining: 35.5s\n",
            "856:\tlearn: 0.3370380\ttotal: 3m 31s\tremaining: 35.2s\n",
            "857:\tlearn: 0.3365969\ttotal: 3m 31s\tremaining: 35s\n",
            "858:\tlearn: 0.3361555\ttotal: 3m 31s\tremaining: 34.7s\n",
            "859:\tlearn: 0.3355608\ttotal: 3m 31s\tremaining: 34.5s\n",
            "860:\tlearn: 0.3350579\ttotal: 3m 31s\tremaining: 34.2s\n",
            "861:\tlearn: 0.3346870\ttotal: 3m 32s\tremaining: 34s\n",
            "862:\tlearn: 0.3342043\ttotal: 3m 32s\tremaining: 33.7s\n",
            "863:\tlearn: 0.3337877\ttotal: 3m 32s\tremaining: 33.5s\n",
            "864:\tlearn: 0.3334192\ttotal: 3m 32s\tremaining: 33.2s\n",
            "865:\tlearn: 0.3329071\ttotal: 3m 32s\tremaining: 33s\n",
            "866:\tlearn: 0.3324468\ttotal: 3m 33s\tremaining: 32.7s\n",
            "867:\tlearn: 0.3320461\ttotal: 3m 33s\tremaining: 32.5s\n",
            "868:\tlearn: 0.3314613\ttotal: 3m 33s\tremaining: 32.2s\n",
            "869:\tlearn: 0.3309316\ttotal: 3m 33s\tremaining: 32s\n",
            "870:\tlearn: 0.3305467\ttotal: 3m 34s\tremaining: 31.7s\n",
            "871:\tlearn: 0.3300473\ttotal: 3m 34s\tremaining: 31.5s\n",
            "872:\tlearn: 0.3294982\ttotal: 3m 34s\tremaining: 31.2s\n",
            "873:\tlearn: 0.3291892\ttotal: 3m 34s\tremaining: 31s\n",
            "874:\tlearn: 0.3288145\ttotal: 3m 34s\tremaining: 30.7s\n",
            "875:\tlearn: 0.3284358\ttotal: 3m 35s\tremaining: 30.5s\n",
            "876:\tlearn: 0.3281704\ttotal: 3m 35s\tremaining: 30.2s\n",
            "877:\tlearn: 0.3278572\ttotal: 3m 35s\tremaining: 30s\n",
            "878:\tlearn: 0.3274741\ttotal: 3m 35s\tremaining: 29.7s\n",
            "879:\tlearn: 0.3269974\ttotal: 3m 35s\tremaining: 29.5s\n",
            "880:\tlearn: 0.3266218\ttotal: 3m 36s\tremaining: 29.2s\n",
            "881:\tlearn: 0.3262694\ttotal: 3m 36s\tremaining: 29s\n",
            "882:\tlearn: 0.3258503\ttotal: 3m 36s\tremaining: 28.7s\n",
            "883:\tlearn: 0.3254594\ttotal: 3m 36s\tremaining: 28.5s\n",
            "884:\tlearn: 0.3249592\ttotal: 3m 37s\tremaining: 28.2s\n",
            "885:\tlearn: 0.3244453\ttotal: 3m 37s\tremaining: 28s\n",
            "886:\tlearn: 0.3238333\ttotal: 3m 37s\tremaining: 27.7s\n",
            "887:\tlearn: 0.3234374\ttotal: 3m 37s\tremaining: 27.5s\n",
            "888:\tlearn: 0.3228299\ttotal: 3m 37s\tremaining: 27.2s\n",
            "889:\tlearn: 0.3225929\ttotal: 3m 38s\tremaining: 26.9s\n",
            "890:\tlearn: 0.3221053\ttotal: 3m 38s\tremaining: 26.7s\n",
            "891:\tlearn: 0.3216841\ttotal: 3m 38s\tremaining: 26.5s\n",
            "892:\tlearn: 0.3214567\ttotal: 3m 38s\tremaining: 26.2s\n",
            "893:\tlearn: 0.3210745\ttotal: 3m 38s\tremaining: 26s\n",
            "894:\tlearn: 0.3206054\ttotal: 3m 39s\tremaining: 25.7s\n",
            "895:\tlearn: 0.3203377\ttotal: 3m 39s\tremaining: 25.5s\n",
            "896:\tlearn: 0.3199113\ttotal: 3m 39s\tremaining: 25.2s\n",
            "897:\tlearn: 0.3195151\ttotal: 3m 39s\tremaining: 25s\n",
            "898:\tlearn: 0.3191828\ttotal: 3m 39s\tremaining: 24.7s\n",
            "899:\tlearn: 0.3187423\ttotal: 3m 40s\tremaining: 24.5s\n",
            "900:\tlearn: 0.3181696\ttotal: 3m 40s\tremaining: 24.2s\n",
            "901:\tlearn: 0.3177326\ttotal: 3m 40s\tremaining: 24s\n",
            "902:\tlearn: 0.3172135\ttotal: 3m 41s\tremaining: 23.8s\n",
            "903:\tlearn: 0.3168538\ttotal: 3m 41s\tremaining: 23.5s\n",
            "904:\tlearn: 0.3164553\ttotal: 3m 42s\tremaining: 23.3s\n",
            "905:\tlearn: 0.3159388\ttotal: 3m 42s\tremaining: 23.1s\n",
            "906:\tlearn: 0.3155593\ttotal: 3m 42s\tremaining: 22.8s\n",
            "907:\tlearn: 0.3150965\ttotal: 3m 43s\tremaining: 22.6s\n",
            "908:\tlearn: 0.3146336\ttotal: 3m 43s\tremaining: 22.4s\n",
            "909:\tlearn: 0.3141721\ttotal: 3m 43s\tremaining: 22.1s\n",
            "910:\tlearn: 0.3136014\ttotal: 3m 44s\tremaining: 21.9s\n",
            "911:\tlearn: 0.3132325\ttotal: 3m 44s\tremaining: 21.6s\n",
            "912:\tlearn: 0.3129076\ttotal: 3m 44s\tremaining: 21.4s\n",
            "913:\tlearn: 0.3124606\ttotal: 3m 44s\tremaining: 21.1s\n",
            "914:\tlearn: 0.3121969\ttotal: 3m 44s\tremaining: 20.9s\n",
            "915:\tlearn: 0.3117937\ttotal: 3m 45s\tremaining: 20.6s\n",
            "916:\tlearn: 0.3112927\ttotal: 3m 45s\tremaining: 20.4s\n",
            "917:\tlearn: 0.3108920\ttotal: 3m 45s\tremaining: 20.1s\n",
            "918:\tlearn: 0.3105721\ttotal: 3m 45s\tremaining: 19.9s\n",
            "919:\tlearn: 0.3100753\ttotal: 3m 45s\tremaining: 19.6s\n",
            "920:\tlearn: 0.3097249\ttotal: 3m 46s\tremaining: 19.4s\n",
            "921:\tlearn: 0.3092675\ttotal: 3m 46s\tremaining: 19.2s\n",
            "922:\tlearn: 0.3088061\ttotal: 3m 46s\tremaining: 18.9s\n",
            "923:\tlearn: 0.3083634\ttotal: 3m 46s\tremaining: 18.7s\n",
            "924:\tlearn: 0.3079849\ttotal: 3m 47s\tremaining: 18.4s\n",
            "925:\tlearn: 0.3076566\ttotal: 3m 47s\tremaining: 18.2s\n",
            "926:\tlearn: 0.3073387\ttotal: 3m 47s\tremaining: 17.9s\n",
            "927:\tlearn: 0.3070562\ttotal: 3m 47s\tremaining: 17.7s\n",
            "928:\tlearn: 0.3068054\ttotal: 3m 47s\tremaining: 17.4s\n",
            "929:\tlearn: 0.3065061\ttotal: 3m 48s\tremaining: 17.2s\n",
            "930:\tlearn: 0.3061709\ttotal: 3m 48s\tremaining: 16.9s\n",
            "931:\tlearn: 0.3056536\ttotal: 3m 48s\tremaining: 16.7s\n",
            "932:\tlearn: 0.3052368\ttotal: 3m 48s\tremaining: 16.4s\n",
            "933:\tlearn: 0.3048279\ttotal: 3m 48s\tremaining: 16.2s\n",
            "934:\tlearn: 0.3044972\ttotal: 3m 49s\tremaining: 15.9s\n",
            "935:\tlearn: 0.3041483\ttotal: 3m 49s\tremaining: 15.7s\n",
            "936:\tlearn: 0.3038381\ttotal: 3m 49s\tremaining: 15.4s\n",
            "937:\tlearn: 0.3035620\ttotal: 3m 49s\tremaining: 15.2s\n",
            "938:\tlearn: 0.3031816\ttotal: 3m 50s\tremaining: 14.9s\n",
            "939:\tlearn: 0.3027465\ttotal: 3m 50s\tremaining: 14.7s\n",
            "940:\tlearn: 0.3022543\ttotal: 3m 50s\tremaining: 14.5s\n",
            "941:\tlearn: 0.3018911\ttotal: 3m 50s\tremaining: 14.2s\n",
            "942:\tlearn: 0.3017170\ttotal: 3m 50s\tremaining: 14s\n",
            "943:\tlearn: 0.3012859\ttotal: 3m 51s\tremaining: 13.7s\n",
            "944:\tlearn: 0.3008145\ttotal: 3m 51s\tremaining: 13.5s\n",
            "945:\tlearn: 0.3003988\ttotal: 3m 51s\tremaining: 13.2s\n",
            "946:\tlearn: 0.2999078\ttotal: 3m 51s\tremaining: 13s\n",
            "947:\tlearn: 0.2995475\ttotal: 3m 51s\tremaining: 12.7s\n",
            "948:\tlearn: 0.2991432\ttotal: 3m 52s\tremaining: 12.5s\n",
            "949:\tlearn: 0.2987089\ttotal: 3m 52s\tremaining: 12.2s\n",
            "950:\tlearn: 0.2983324\ttotal: 3m 52s\tremaining: 12s\n",
            "951:\tlearn: 0.2980234\ttotal: 3m 52s\tremaining: 11.7s\n",
            "952:\tlearn: 0.2975938\ttotal: 3m 53s\tremaining: 11.5s\n",
            "953:\tlearn: 0.2973058\ttotal: 3m 53s\tremaining: 11.2s\n",
            "954:\tlearn: 0.2969756\ttotal: 3m 53s\tremaining: 11s\n",
            "955:\tlearn: 0.2966562\ttotal: 3m 53s\tremaining: 10.8s\n",
            "956:\tlearn: 0.2962484\ttotal: 3m 53s\tremaining: 10.5s\n",
            "957:\tlearn: 0.2958909\ttotal: 3m 54s\tremaining: 10.3s\n",
            "958:\tlearn: 0.2954536\ttotal: 3m 54s\tremaining: 10s\n",
            "959:\tlearn: 0.2950160\ttotal: 3m 54s\tremaining: 9.79s\n",
            "960:\tlearn: 0.2946397\ttotal: 3m 55s\tremaining: 9.54s\n",
            "961:\tlearn: 0.2942784\ttotal: 3m 55s\tremaining: 9.3s\n",
            "962:\tlearn: 0.2939082\ttotal: 3m 55s\tremaining: 9.06s\n",
            "963:\tlearn: 0.2934037\ttotal: 3m 56s\tremaining: 8.82s\n",
            "964:\tlearn: 0.2930358\ttotal: 3m 56s\tremaining: 8.58s\n",
            "965:\tlearn: 0.2927189\ttotal: 3m 56s\tremaining: 8.34s\n",
            "966:\tlearn: 0.2923261\ttotal: 3m 57s\tremaining: 8.1s\n",
            "967:\tlearn: 0.2920582\ttotal: 3m 57s\tremaining: 7.85s\n",
            "968:\tlearn: 0.2917280\ttotal: 3m 57s\tremaining: 7.61s\n",
            "969:\tlearn: 0.2913972\ttotal: 3m 58s\tremaining: 7.36s\n",
            "970:\tlearn: 0.2910855\ttotal: 3m 58s\tremaining: 7.11s\n",
            "971:\tlearn: 0.2906659\ttotal: 3m 58s\tremaining: 6.87s\n",
            "972:\tlearn: 0.2904803\ttotal: 3m 58s\tremaining: 6.62s\n",
            "973:\tlearn: 0.2901107\ttotal: 3m 58s\tremaining: 6.38s\n",
            "974:\tlearn: 0.2897686\ttotal: 3m 59s\tremaining: 6.13s\n",
            "975:\tlearn: 0.2894399\ttotal: 3m 59s\tremaining: 5.88s\n",
            "976:\tlearn: 0.2892857\ttotal: 3m 59s\tremaining: 5.64s\n",
            "977:\tlearn: 0.2889306\ttotal: 3m 59s\tremaining: 5.39s\n",
            "978:\tlearn: 0.2886153\ttotal: 3m 59s\tremaining: 5.15s\n",
            "979:\tlearn: 0.2883613\ttotal: 4m\tremaining: 4.9s\n",
            "980:\tlearn: 0.2878970\ttotal: 4m\tremaining: 4.66s\n",
            "981:\tlearn: 0.2875827\ttotal: 4m\tremaining: 4.41s\n",
            "982:\tlearn: 0.2872647\ttotal: 4m\tremaining: 4.16s\n",
            "983:\tlearn: 0.2868528\ttotal: 4m 1s\tremaining: 3.92s\n",
            "984:\tlearn: 0.2865528\ttotal: 4m 1s\tremaining: 3.67s\n",
            "985:\tlearn: 0.2862393\ttotal: 4m 1s\tremaining: 3.43s\n",
            "986:\tlearn: 0.2859382\ttotal: 4m 1s\tremaining: 3.18s\n",
            "987:\tlearn: 0.2856303\ttotal: 4m 1s\tremaining: 2.94s\n",
            "988:\tlearn: 0.2853659\ttotal: 4m 2s\tremaining: 2.69s\n",
            "989:\tlearn: 0.2850071\ttotal: 4m 2s\tremaining: 2.45s\n",
            "990:\tlearn: 0.2847075\ttotal: 4m 2s\tremaining: 2.2s\n",
            "991:\tlearn: 0.2843663\ttotal: 4m 2s\tremaining: 1.96s\n",
            "992:\tlearn: 0.2840120\ttotal: 4m 2s\tremaining: 1.71s\n",
            "993:\tlearn: 0.2837899\ttotal: 4m 3s\tremaining: 1.47s\n",
            "994:\tlearn: 0.2833344\ttotal: 4m 3s\tremaining: 1.22s\n",
            "995:\tlearn: 0.2830093\ttotal: 4m 3s\tremaining: 978ms\n",
            "996:\tlearn: 0.2826509\ttotal: 4m 3s\tremaining: 734ms\n",
            "997:\tlearn: 0.2822664\ttotal: 4m 4s\tremaining: 489ms\n",
            "998:\tlearn: 0.2819363\ttotal: 4m 4s\tremaining: 245ms\n",
            "999:\tlearn: 0.2816771\ttotal: 4m 4s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7ab466663c70>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "rxVwgYrsw7yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkGe1nmDw9Ti",
        "outputId": "f8452b85-9423-4f3b-c9b5-44c110b846c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5023780878577142"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Artificial Neural Network"
      ],
      "metadata": {
        "id": "ZLaJhYuNyYb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X_train_ann = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "y_train_ann = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "y_test_ann = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "X_test_ann = tf.convert_to_tensor(X_test, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "YrjcuDv30pNe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=2048, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=8192, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=16384, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=32768, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=65536, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=1))"
      ],
      "metadata": {
        "id": "XBaUV2P4yy44"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "metadata": {
        "id": "sK-6gbnUy96S"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train_ann, y_train_ann, batch_size = 32, epochs = 5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3TK6rU3Zy_su",
        "outputId": "f803e1b2-4983-4d55-cf2c-ddd5db9be124"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 16615245611008.0000\n",
            "Epoch 2/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 8969104916480.0000\n",
            "Epoch 3/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 5624463097856.0000\n",
            "Epoch 4/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 7668771061760.0000\n",
            "Epoch 5/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 5344789528576.0000\n",
            "Epoch 6/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4103051149312.0000\n",
            "Epoch 7/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 3687667728384.0000\n",
            "Epoch 8/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 4225903886336.0000\n",
            "Epoch 9/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 6060336742400.0000\n",
            "Epoch 10/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4637614669824.0000\n",
            "Epoch 11/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - loss: 4070086279168.0000\n",
            "Epoch 12/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 3667677151232.0000\n",
            "Epoch 13/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 3740149743616.0000\n",
            "Epoch 14/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4877253607424.0000\n",
            "Epoch 15/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3914884448256.0000\n",
            "Epoch 16/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3832259805184.0000\n",
            "Epoch 17/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4380785377280.0000\n",
            "Epoch 18/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3856909205504.0000\n",
            "Epoch 19/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 5445831360512.0000\n",
            "Epoch 20/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 5386725752832.0000\n",
            "Epoch 21/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4177385488384.0000\n",
            "Epoch 22/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4071691649024.0000\n",
            "Epoch 23/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3069828399104.0000\n",
            "Epoch 24/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - loss: 4441788383232.0000\n",
            "Epoch 25/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3761858412544.0000\n",
            "Epoch 26/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 9009873551360.0000\n",
            "Epoch 27/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 9954291351552.0000\n",
            "Epoch 28/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - loss: 3780087644160.0000\n",
            "Epoch 29/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3839471386624.0000\n",
            "Epoch 30/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3647380127744.0000\n",
            "Epoch 31/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4202739531776.0000\n",
            "Epoch 32/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 4034730655744.0000\n",
            "Epoch 33/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 3677285777408.0000\n",
            "Epoch 34/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - loss: 3251509133312.0000\n",
            "Epoch 35/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3463787839488.0000\n",
            "Epoch 36/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4275786219520.0000\n",
            "Epoch 37/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4007994589184.0000\n",
            "Epoch 38/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3839754502144.0000\n",
            "Epoch 39/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3452729556992.0000\n",
            "Epoch 40/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 4638820532224.0000\n",
            "Epoch 41/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4961743667200.0000\n",
            "Epoch 42/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3453131161600.0000\n",
            "Epoch 43/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4144783949824.0000\n",
            "Epoch 44/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3339704598528.0000\n",
            "Epoch 45/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4306347229184.0000\n",
            "Epoch 46/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4731184873472.0000\n",
            "Epoch 47/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3808608649216.0000\n",
            "Epoch 48/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4560185196544.0000\n",
            "Epoch 49/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4396898582528.0000\n",
            "Epoch 50/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - loss: 4215673716736.0000\n",
            "Epoch 51/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3651211362304.0000\n",
            "Epoch 52/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3315103694848.0000\n",
            "Epoch 53/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 4116419444736.0000\n",
            "Epoch 54/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3833756647424.0000\n",
            "Epoch 55/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 3026702827520.0000\n",
            "Epoch 56/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 4196490280960.0000\n",
            "Epoch 57/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3516789686272.0000\n",
            "Epoch 58/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 3555931717632.0000\n",
            "Epoch 59/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4833966292992.0000\n",
            "Epoch 60/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 3337003991040.0000\n",
            "Epoch 61/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3625349283840.0000\n",
            "Epoch 62/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3638585982976.0000\n",
            "Epoch 63/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4004991991808.0000\n",
            "Epoch 64/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4260240293888.0000\n",
            "Epoch 65/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3627139989504.0000\n",
            "Epoch 66/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4240132014080.0000\n",
            "Epoch 67/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3615505776640.0000\n",
            "Epoch 68/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 5256772059136.0000\n",
            "Epoch 69/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - loss: 3485470294016.0000\n",
            "Epoch 70/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 4519191117824.0000\n",
            "Epoch 71/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 4316213805056.0000\n",
            "Epoch 72/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 3177676013568.0000\n",
            "Epoch 73/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 4038424788992.0000\n",
            "Epoch 74/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - loss: 3813885607936.0000\n",
            "Epoch 75/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3991259840512.0000\n",
            "Epoch 76/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3604106706944.0000\n",
            "Epoch 77/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 3824030056448.0000\n",
            "Epoch 78/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3668440776704.0000\n",
            "Epoch 79/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3096619778048.0000\n",
            "Epoch 80/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 3348251017216.0000\n",
            "Epoch 81/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 3429195317248.0000\n",
            "Epoch 82/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 3580408627200.0000\n",
            "Epoch 83/2000\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 3985660182528.0000\n",
            "Epoch 84/2000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-89910dcd985b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_ann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test_ann)"
      ],
      "metadata": {
        "id": "ZoTH3ZxAzd2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test_ann, y_pred)"
      ],
      "metadata": {
        "id": "lET50voUzh3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}